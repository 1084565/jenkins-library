{
    "docs": [
        {
            "location": "/", 
            "text": "Project \"Piper\" - extended library documentation\n\n\nOn the following pages, you can find documentation for all steps and scripts\ncontained in the library of project \"Piper\".\n\n\nWe have also compiled a list of plugins that are required for the library to\nwork.\n\n\nFor information on the project and installation of the library, please have a\nlook at our \nREADME.md\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#project-piper-extended-library-documentation", 
            "text": "On the following pages, you can find documentation for all steps and scripts\ncontained in the library of project \"Piper\".  We have also compiled a list of plugins that are required for the library to\nwork.  For information on the project and installation of the library, please have a\nlook at our  README.md .", 
            "title": "Project \"Piper\" - extended library documentation"
        }, 
        {
            "location": "/steps/artifactSetVersion/", 
            "text": "artifactSetVersion\n\n\nDescription\n\n\nThe continuous delivery process requires that each build is done with a unique version number.\n\n\nThe version generated using this step will contain:\n\n\n\n\nVersion (major.minor.patch) from descriptor file in master repository is preserved. Developers should be able to autonomously decide on increasing either part of this version number.\n\n\nTimestamp\n\n\nCommitId (by default the long version of the hash)\n\n\n\n\nOptionally, but enabled by default, the new version is pushed as a new tag into the source code repository (e.g. GitHub).\nIf this option is chosen, git credentials and the repository URL needs to be provided.\nSince you might not want to configure the git credentials in Jenkins, committing and pushing can be disabled using the \ncommitVersion\n parameter as described below.\nIf you require strict reproducibility of your builds, this should be used.\n\n\nPrerequsites\n\n\nnone\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nno\n\n\nempty \ncommonPipelineEnvironment\n\n\n\n\n\n\n\n\nartifactType\n\n\nno\n\n\n\n\n'appContainer'\n\n\n\n\n\n\nbuildTool\n\n\nno\n\n\nmaven\n\n\nmaven, docker\n\n\n\n\n\n\ncommitVersion\n\n\nno\n\n\ntrue\n\n\ntrue\n, \nfalse\n\n\n\n\n\n\ndockerVersionSource\n\n\nno\n\n\n''\n\n\nFROM, (ENV name),appVersion\n\n\n\n\n\n\nfilePath\n\n\nno\n\n\nbuildTool=\nmaven\n: pom.xml \ndocker: Dockerfile\n\n\n\n\n\n\n\n\ngitCommitId\n\n\nno\n\n\nGitUtils.getGitCommitId()\n\n\n\n\n\n\n\n\ngitCredentialsId\n\n\nIf \ncommitVersion\n is \ntrue\n\n\nas defined in custom configuration\n\n\n\n\n\n\n\n\ngitUserEMail\n\n\nno\n\n\n\n\n\n\n\n\n\n\ngitUserName\n\n\nno\n\n\n\n\n\n\n\n\n\n\ngitSshUrl\n\n\nIf \ncommitVersion\n is \ntrue\n\n\n\n\n\n\n\n\n\n\ntagPrefix\n\n\nno\n\n\n'build_'\n\n\n\n\n\n\n\n\ntimestamp\n\n\nno\n\n\ncurrent time in format according to \ntimestampTemplate\n\n\n\n\n\n\n\n\ntimestampTemplate\n\n\nno\n\n\n%Y%m%d%H%M%S\n\n\n\n\n\n\n\n\nversioningTemplate\n\n\nno\n\n\ndepending on \nbuildTool\nmaven: \n${version}-${timestamp}${commitId?\"_\"+commitId:\"\"}\n\n\n\n\n\n\n\n\n\n\n\n\nscript\n defines the global script environment of the Jenkinsfile run. Typically \nthis\n is passed to this parameter. This allows the function to access the \ncommonPipelineEnvironment\n for retrieving e.g. configuration parameters.\n\n\nartifactType\n defines the type of the artifact.\n\n\nbuildTool\n defines the tool which is used for building the artifact.\n\n\ncommitVersion\n controls if the changed version is committed and pushed to the git repository. If this is enabled (which is the default), you need to provide \ngitCredentialsId\n and \ngitSshUrl\n.\n\n\n\n\ndockerVersionSource\n specifies the source to be used for the main version which is used for generating the automatic version.\n\n\n\n\nThis can either be the version of the base image - as retrieved from the \nFROM\n statement within the Dockerfile, e.g. \nFROM jenkins:2.46.2\n\n\nAlternatively the name of an environment variable defined in the Docker image can be used which contains the version number, e.g. \nENV MY_VERSION 1.2.3\n\n\nThe third option \nappVersion\n applies only to the artifactType \nappContainer\n. Here the version of the app which is packaged into the container will be used as version for the container itself.\n\n\n\n\n\n\n\n\nUsing \nfilePath\n you could define a custom path to the descriptor file.\n\n\n\n\ngitCommitId\n defines the version prefix of the automatically generated version. By default it will take the long commitId hash. You could pass any other string (e.g. the short commitId hash) to be used. In case you don't want to have the gitCommitId added to the automatic versioning string you could set the value to an empty string: \n''\n.\n\n\ngitCredentialsId\ndefines the ssh git credentials to be used for writing the tag.\n\n\nThe parameters \ngitUserName\n and \ngitUserEMail\n allow to overwrite the global git settings available on your Jenkins server\n\n\ngitSshUrl\n defines the git ssh url to the source code repository.\n\n\ntagPrefix\n defines the prefix wich is used for the git tag which is written during the versioning run.\n\n\ntimestamp\n defines the timestamp to be used in the automatic version string. You could overwrite the default behavior by explicitly setting this string.\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\nartifactType\n\n\nbuildTool\n\n\ncommitVersion\n\n\ndockerVersionSource\n\n\nfilePath\n\n\ngitCredentialsId\n\n\ngitUserEMail\n\n\ngitUserName\n\n\ngitSshUrl\n\n\ntagPrefix\n\n\ntimestamp\n\n\ntimestampTemplate\n\n\nversioningTemplate\n\n\n\n\nExample\n\n\nartifactSetVersion\n \nscript:\n \nthis\n,\n \nbuildTool:\n \nmaven", 
            "title": "artifactSetVersion"
        }, 
        {
            "location": "/steps/artifactSetVersion/#artifactsetversion", 
            "text": "", 
            "title": "artifactSetVersion"
        }, 
        {
            "location": "/steps/artifactSetVersion/#description", 
            "text": "The continuous delivery process requires that each build is done with a unique version number.  The version generated using this step will contain:   Version (major.minor.patch) from descriptor file in master repository is preserved. Developers should be able to autonomously decide on increasing either part of this version number.  Timestamp  CommitId (by default the long version of the hash)   Optionally, but enabled by default, the new version is pushed as a new tag into the source code repository (e.g. GitHub).\nIf this option is chosen, git credentials and the repository URL needs to be provided.\nSince you might not want to configure the git credentials in Jenkins, committing and pushing can be disabled using the  commitVersion  parameter as described below.\nIf you require strict reproducibility of your builds, this should be used.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/artifactSetVersion/#prerequsites", 
            "text": "none", 
            "title": "Prerequsites"
        }, 
        {
            "location": "/steps/artifactSetVersion/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  no  empty  commonPipelineEnvironment     artifactType  no   'appContainer'    buildTool  no  maven  maven, docker    commitVersion  no  true  true ,  false    dockerVersionSource  no  ''  FROM, (ENV name),appVersion    filePath  no  buildTool= maven : pom.xml  docker: Dockerfile     gitCommitId  no  GitUtils.getGitCommitId()     gitCredentialsId  If  commitVersion  is  true  as defined in custom configuration     gitUserEMail  no      gitUserName  no      gitSshUrl  If  commitVersion  is  true      tagPrefix  no  'build_'     timestamp  no  current time in format according to  timestampTemplate     timestampTemplate  no  %Y%m%d%H%M%S     versioningTemplate  no  depending on  buildTool maven:  ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"}       script  defines the global script environment of the Jenkinsfile run. Typically  this  is passed to this parameter. This allows the function to access the  commonPipelineEnvironment  for retrieving e.g. configuration parameters.  artifactType  defines the type of the artifact.  buildTool  defines the tool which is used for building the artifact.  commitVersion  controls if the changed version is committed and pushed to the git repository. If this is enabled (which is the default), you need to provide  gitCredentialsId  and  gitSshUrl .   dockerVersionSource  specifies the source to be used for the main version which is used for generating the automatic version.   This can either be the version of the base image - as retrieved from the  FROM  statement within the Dockerfile, e.g.  FROM jenkins:2.46.2  Alternatively the name of an environment variable defined in the Docker image can be used which contains the version number, e.g.  ENV MY_VERSION 1.2.3  The third option  appVersion  applies only to the artifactType  appContainer . Here the version of the app which is packaged into the container will be used as version for the container itself.     Using  filePath  you could define a custom path to the descriptor file.   gitCommitId  defines the version prefix of the automatically generated version. By default it will take the long commitId hash. You could pass any other string (e.g. the short commitId hash) to be used. In case you don't want to have the gitCommitId added to the automatic versioning string you could set the value to an empty string:  '' .  gitCredentialsId defines the ssh git credentials to be used for writing the tag.  The parameters  gitUserName  and  gitUserEMail  allow to overwrite the global git settings available on your Jenkins server  gitSshUrl  defines the git ssh url to the source code repository.  tagPrefix  defines the prefix wich is used for the git tag which is written during the versioning run.  timestamp  defines the timestamp to be used in the automatic version string. You could overwrite the default behavior by explicitly setting this string.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/artifactSetVersion/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   artifactType  buildTool  commitVersion  dockerVersionSource  filePath  gitCredentialsId  gitUserEMail  gitUserName  gitSshUrl  tagPrefix  timestamp  timestampTemplate  versioningTemplate", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/artifactSetVersion/#example", 
            "text": "artifactSetVersion   script:   this ,   buildTool:   maven", 
            "title": "Example"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/", 
            "text": "checkChangeInDevelopment\n\n\nDescription\n\n\nChecks if a Change Document is in status 'in development'. The change document id is retrieved from the git commit history. The change document id\ncan also be provided via parameter \nchangeDocumentId\n. Any value provided as parameter has a higher precedence than a value from the commit history.\n\n\nBy default the git commit messages between \norigin/master\n and \nHEAD\n are scanned for a line like \nChangeDocument : \nchangeDocumentId\n. The commit\nrange and the pattern can be configured. For details see 'parameters' table. \n\n\nPrerequisites\n\n\n\n\nChange Management Client 2.0.0 or compatible version\n - available for download on Maven Central.\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nchangeDocumentId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncredentialsId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nendpoint\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ngitFrom\n\n\nno\n\n\norigin/master\n\n\n\n\n\n\n\n\ngitTo\n\n\nno\n\n\nHEAD\n\n\n\n\n\n\n\n\ngitChangeDocumentLabel\n\n\nno\n\n\nChangeDocument\\s?:\n\n\nregex pattern\n\n\n\n\n\n\ngitFormat\n\n\nno\n\n\n%b\n\n\nsee \ngit log --help\n\n\n\n\n\n\n\n\n\n\nscript\n - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the \nthis\n parameter, as in \nscript: this\n. This allows the function to access the \ncommonPipelineEnvironment\n for retrieving, for example, configuration parameters.\n\n\nchangeDocumentId\n - The id of the change document to transport. If not provided, it is retrieved from the git commit history.\n\n\ncredentialsId\n - The credentials to connect to the Solution Manager.\n\n\nendpoint\n - The address of the Solution Manager.\n\n\ngitFrom\n - The starting point for retrieving the change document id\n\n\ngitTo\n - The end point for retrieving the change document id\n\n\ngitChangeDocumentLabel\n - A pattern used for identifying lines holding the change document id.\n\n\ngitFormat\n - Specifies what part of the commit is scanned. By default the body of the commit message is scanned.\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\ncredentialsId\n\n\nendpoint\n\n\n\n\nReturn value\n\n\ntrue\n in case the change document is in status 'in development'. Otherwise an hudson.AbortException is thrown. In case \nfailIfStatusIsNotInDevelopment\n\nis set to \nfalse\n, \nfalse\n is returned in case the change document is not in status 'in development'\n\n\nExceptions\n\n\n\n\nAbortException\n:\n\n\nIf the change id is not provided via parameter and if the change document id cannot be retrieved from the commit history.\n\n\nIf the change is not in status \nin development\n. In this case no exception will be thrown when \nfailIfStatusIsNotInDevelopment\n is set to \nfalse\n.\n\n\n\n\n\n\n\n\nExample\n\n\n    \ncheckChangeInDevelopment\n \nscript:\nthis", 
            "title": "checkChangeInDevelopment"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/#checkchangeindevelopment", 
            "text": "", 
            "title": "checkChangeInDevelopment"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/#description", 
            "text": "Checks if a Change Document is in status 'in development'. The change document id is retrieved from the git commit history. The change document id\ncan also be provided via parameter  changeDocumentId . Any value provided as parameter has a higher precedence than a value from the commit history.  By default the git commit messages between  origin/master  and  HEAD  are scanned for a line like  ChangeDocument :  changeDocumentId . The commit\nrange and the pattern can be configured. For details see 'parameters' table.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/#prerequisites", 
            "text": "Change Management Client 2.0.0 or compatible version  - available for download on Maven Central.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  yes      changeDocumentId  yes      credentialsId  yes      endpoint  yes      gitFrom  no  origin/master     gitTo  no  HEAD     gitChangeDocumentLabel  no  ChangeDocument\\s?:  regex pattern    gitFormat  no  %b  see  git log --help      script  - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the  this  parameter, as in  script: this . This allows the function to access the  commonPipelineEnvironment  for retrieving, for example, configuration parameters.  changeDocumentId  - The id of the change document to transport. If not provided, it is retrieved from the git commit history.  credentialsId  - The credentials to connect to the Solution Manager.  endpoint  - The address of the Solution Manager.  gitFrom  - The starting point for retrieving the change document id  gitTo  - The end point for retrieving the change document id  gitChangeDocumentLabel  - A pattern used for identifying lines holding the change document id.  gitFormat  - Specifies what part of the commit is scanned. By default the body of the commit message is scanned.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   credentialsId  endpoint", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/#return-value", 
            "text": "true  in case the change document is in status 'in development'. Otherwise an hudson.AbortException is thrown. In case  failIfStatusIsNotInDevelopment \nis set to  false ,  false  is returned in case the change document is not in status 'in development'", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/#exceptions", 
            "text": "AbortException :  If the change id is not provided via parameter and if the change document id cannot be retrieved from the commit history.  If the change is not in status  in development . In this case no exception will be thrown when  failIfStatusIsNotInDevelopment  is set to  false .", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/checkChangeInDevelopment/#example", 
            "text": "checkChangeInDevelopment   script: this", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/", 
            "text": "commonPipelineEnvironment\n\n\nDescription\n\n\nProvides project specific settings.\n\n\nPrerequisites\n\n\nnone\n\n\nMethod details\n\n\ngetArtifactVersion()\n\n\nDescription\n\n\nReturns the version of the artifact which is build in the pipeline.\n\n\nParameters\n\n\nnone\n\n\nReturn value\n\n\nA \nString\n containing the version.\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ndef\n \nmyVersion\n \n=\n \ncommonPipelineEnvironment\n.\ngetArtifactVersion\n()\n\n\n\n\n\nsetArtifactVersion(version)\n\n\nDescription\n\n\nSets the version of the artifact which is build in the pipeline.\n\n\nParameters\n\n\nnone\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ncommonPipelineEnvironment\n.\nsetArtifactVersion\n(\n1.2.3\n)\n\n\n\n\n\ngetConfigProperties()\n\n\nDescription\n\n\nReturns the map of project specific configuration properties. No defensive copy is created.\nWrite operations to the map are visible further down in the pipeline.\n\n\nParameters\n\n\nnone\n\n\nReturn value\n\n\nA map containing project specific configuration properties.\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ncommonPipelineEnvironment\n.\ngetConfigProperties\n()\n\n\n\n\n\nsetConfigProperties(configuration)\n\n\nDescription\n\n\nSets the map of configuration properties. Any existing map is overwritten.\n\n\nParameters\n\n\n\n\nconfiguration\n - A map containing the new configuration\n\n\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ncommonPipelineEnvironment\n.\nsetConfigProperties\n([\nDEPLOY_HOST:\n \ndeploy-host.com\n,\n \nDEPLOY_ACCOUNT:\n \ndeploy-account\n])\n\n\n\n\n\ngetConfigProperty(property)\n\n\nDescription\n\n\nGets a specific value from the configuration property.\n\n\nParameters\n\n\n\n\nproperty\n - The key of the property.\n\n\n\n\nReturn value\n\n\n\n\nThe value associated with key \nproperty\n. \nnull\n is returned in case the property does not exist.\n\n\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ncommonPipelineEnvironment\n.\ngetConfigProperty\n(\nDEPLOY_HOST\n)\n\n\n\n\n\nsetConfigProperty(property, value)\n\n\nDescription\n\n\nSets property \nproperty\n with value \nvalue\n. Any existing property with key \nproperty\n is overwritten.\n\n\nParameters\n\n\n\n\nproperty\n - The key of the property.\n\n\nvalue\n - The value of the property.\n\n\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ncommonPipelineEnvironment\n.\nsetConfigProperty\n(\nDEPLOY_HOST\n,\n \nmy-deploy-host.com\n)\n\n\n\n\n\ngetInfluxCustomData()\n\n\nDescription\n\n\nReturns the Influx custom data which can be collected during pipeline run.\n\n\nParameters\n\n\nnone\n\n\nReturn value\n\n\nA \nMap\n containing the data collected.\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ndef\n \nmyInfluxData\n \n=\n \ncommonPipelineEnvironment\n.\ngetInfluxCustomData\n()\n\n\n\n\n\ngetInfluxCustomDataMap()\n\n\nDescription\n\n\nReturns the Influx custom data map which can be collected during pipeline run.\nIt is used for example by step \ninfluxWriteData\n.\nThe data map is a map of maps, like \n[pipeline_data: [:], my_measurement: [:]]\n\nEach map inside the map represents a dedicated measurement in the InfluxDB.\n\n\nParameters\n\n\nnone\n\n\nReturn value\n\n\nA \nMap\n containing a \nMap\ns with data collected.\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ndef\n \nmyInfluxDataMap\n \n=\n \ncommonPipelineEnvironment\n.\ngetInfluxCustomDataMap\n()\n\n\n\n\n\ngetMtarFileName()\n\n\nDescription\n\n\nReturns the path of the mtar archive file.\n\n\nParameters\n\n\nnone\n\n\nReturn value\n\n\nThe path of the mtar archive file.\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ncommonPipelineEnvironment\n.\ngetMtarFileName\n()\n\n\n\n\n\nsetMtarFileName(name)\n\n\nDescription\n\n\nSets the path of the mtar archive file. Any old value is discarded.\n\n\nParameters\n\n\n\n\nmtarFilePath\n - The path of the mtar archive file name.\n\n\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ncommonPipelineEnvironment\n.\nsetMtarFileName\n(\npath/to/foo.mtar\n)\n\n\n\n\n\ngetPipelineMeasurement(measurementName)\n\n\nDescription\n\n\nReturns the value of a specific pipeline measurement.\nThe measurements are collected with step \ndurationMeasure\n\n\nParameters\n\n\nName of the measurement\n\n\nReturn value\n\n\nValue of the measurement\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ndef\n \nmyMeasurementValue\n \n=\n \ncommonPipelineEnvironment\n.\ngetPipelineMeasurement\n(\nbuild_stage_duration\n)\n\n\n\n\n\nsetPipelineMeasurement(measurementName, value)\n\n\nDescription\n\n\nThis is an internal function!\n\nSets the value of a specific pipeline measurement.\nPlease use the step \ndurationMeasure\n in a pipeline, instead.\n\n\nParameters\n\n\nName of the measurement and its value.\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\ncommonPipelineEnvironment\n.\nsetPipelineMeasurement\n(\nbuild_stage_duration\n,\n \n2345\n)", 
            "title": "commonPipelineEnvironment"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#commonpipelineenvironment", 
            "text": "", 
            "title": "commonPipelineEnvironment"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description", 
            "text": "Provides project specific settings.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#prerequisites", 
            "text": "none", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#method-details", 
            "text": "", 
            "title": "Method details"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#getartifactversion", 
            "text": "", 
            "title": "getArtifactVersion()"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_1", 
            "text": "Returns the version of the artifact which is build in the pipeline.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters", 
            "text": "none", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value", 
            "text": "A  String  containing the version.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example", 
            "text": "def   myVersion   =   commonPipelineEnvironment . getArtifactVersion ()", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#setartifactversionversion", 
            "text": "", 
            "title": "setArtifactVersion(version)"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_2", 
            "text": "Sets the version of the artifact which is build in the pipeline.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_1", 
            "text": "none", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_1", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_1", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_1", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_1", 
            "text": "commonPipelineEnvironment . setArtifactVersion ( 1.2.3 )", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#getconfigproperties", 
            "text": "", 
            "title": "getConfigProperties()"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_3", 
            "text": "Returns the map of project specific configuration properties. No defensive copy is created.\nWrite operations to the map are visible further down in the pipeline.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_2", 
            "text": "none", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_2", 
            "text": "A map containing project specific configuration properties.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_2", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_2", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_2", 
            "text": "commonPipelineEnvironment . getConfigProperties ()", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#setconfigpropertiesconfiguration", 
            "text": "", 
            "title": "setConfigProperties(configuration)"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_4", 
            "text": "Sets the map of configuration properties. Any existing map is overwritten.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_3", 
            "text": "configuration  - A map containing the new configuration", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_3", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_3", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_3", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_3", 
            "text": "commonPipelineEnvironment . setConfigProperties ([ DEPLOY_HOST:   deploy-host.com ,   DEPLOY_ACCOUNT:   deploy-account ])", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#getconfigpropertyproperty", 
            "text": "", 
            "title": "getConfigProperty(property)"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_5", 
            "text": "Gets a specific value from the configuration property.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_4", 
            "text": "property  - The key of the property.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_4", 
            "text": "The value associated with key  property .  null  is returned in case the property does not exist.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_4", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_4", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_4", 
            "text": "commonPipelineEnvironment . getConfigProperty ( DEPLOY_HOST )", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#setconfigpropertyproperty-value", 
            "text": "", 
            "title": "setConfigProperty(property, value)"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_6", 
            "text": "Sets property  property  with value  value . Any existing property with key  property  is overwritten.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_5", 
            "text": "property  - The key of the property.  value  - The value of the property.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_5", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_5", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_5", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_5", 
            "text": "commonPipelineEnvironment . setConfigProperty ( DEPLOY_HOST ,   my-deploy-host.com )", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#getinfluxcustomdata", 
            "text": "", 
            "title": "getInfluxCustomData()"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_7", 
            "text": "Returns the Influx custom data which can be collected during pipeline run.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_6", 
            "text": "none", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_6", 
            "text": "A  Map  containing the data collected.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_6", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_6", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_6", 
            "text": "def   myInfluxData   =   commonPipelineEnvironment . getInfluxCustomData ()", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#getinfluxcustomdatamap", 
            "text": "", 
            "title": "getInfluxCustomDataMap()"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_8", 
            "text": "Returns the Influx custom data map which can be collected during pipeline run.\nIt is used for example by step  influxWriteData .\nThe data map is a map of maps, like  [pipeline_data: [:], my_measurement: [:]] \nEach map inside the map represents a dedicated measurement in the InfluxDB.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_7", 
            "text": "none", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_7", 
            "text": "A  Map  containing a  Map s with data collected.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_7", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_7", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_7", 
            "text": "def   myInfluxDataMap   =   commonPipelineEnvironment . getInfluxCustomDataMap ()", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#getmtarfilename", 
            "text": "", 
            "title": "getMtarFileName()"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_9", 
            "text": "Returns the path of the mtar archive file.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_8", 
            "text": "none", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_8", 
            "text": "The path of the mtar archive file.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_8", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_8", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_8", 
            "text": "commonPipelineEnvironment . getMtarFileName ()", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#setmtarfilenamename", 
            "text": "", 
            "title": "setMtarFileName(name)"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_10", 
            "text": "Sets the path of the mtar archive file. Any old value is discarded.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_9", 
            "text": "mtarFilePath  - The path of the mtar archive file name.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_9", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_9", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_9", 
            "text": "commonPipelineEnvironment . setMtarFileName ( path/to/foo.mtar )", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#getpipelinemeasurementmeasurementname", 
            "text": "", 
            "title": "getPipelineMeasurement(measurementName)"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_11", 
            "text": "Returns the value of a specific pipeline measurement.\nThe measurements are collected with step  durationMeasure", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_10", 
            "text": "Name of the measurement", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_9", 
            "text": "Value of the measurement", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_10", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_10", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_10", 
            "text": "def   myMeasurementValue   =   commonPipelineEnvironment . getPipelineMeasurement ( build_stage_duration )", 
            "title": "Example"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#setpipelinemeasurementmeasurementname-value", 
            "text": "", 
            "title": "setPipelineMeasurement(measurementName, value)"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#description_12", 
            "text": "This is an internal function! \nSets the value of a specific pipeline measurement.\nPlease use the step  durationMeasure  in a pipeline, instead.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#parameters_11", 
            "text": "Name of the measurement and its value.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#return-value_10", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#side-effects_11", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#exceptions_11", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/commonPipelineEnvironment/#example_11", 
            "text": "commonPipelineEnvironment . setPipelineMeasurement ( build_stage_duration ,   2345 )", 
            "title": "Example"
        }, 
        {
            "location": "/steps/dockerExecute/", 
            "text": "dockerExecute\n\n\nDescription\n\n\nExecutes a closure inside a docker container with the specified docker image. \nThe workspace is mounted into the docker image.\nProxy environment variables defined on the Jenkins machine are also available in the Docker container.\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\ndockerImage\n\n\nno\n\n\n''\n\n\n\n\n\n\n\n\ndockerEnvVars\n\n\nno\n\n\n[:]\n\n\n\n\n\n\n\n\ndockerOptions\n\n\nno\n\n\n''\n\n\n\n\n\n\n\n\ndockerVolumeBind\n\n\nno\n\n\n[:]\n\n\n\n\n\n\n\n\n\n\n\n\ndockerImage\n Name of the docker image that should be used. If empty, Docker is not used.\n\n\ndockerEnvVars\n Environment variables to set in the container, e.g. [http_proxy:'proxy:8080']\n\n\ndockerOptions\n Docker options to be set when starting the container. It can be a list or a string.\n\n\ndockerVolumeBind\n Volumes that should be mounted into the container.\n\n\n\n\nStep configuration\n\n\nNone\n\n\nExceptions\n\n\nNone\n\n\nExample\n\n\ndockerExecute\n(\ndockerImage:\n \nmaven:3.5-jdk-7\n){\n\n    \nsh\n \nmvn clean install\n\n\n}", 
            "title": "dockerExecute"
        }, 
        {
            "location": "/steps/dockerExecute/#dockerexecute", 
            "text": "", 
            "title": "dockerExecute"
        }, 
        {
            "location": "/steps/dockerExecute/#description", 
            "text": "Executes a closure inside a docker container with the specified docker image. \nThe workspace is mounted into the docker image.\nProxy environment variables defined on the Jenkins machine are also available in the Docker container.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/dockerExecute/#parameters", 
            "text": "parameter  mandatory  default  possible values      dockerImage  no  ''     dockerEnvVars  no  [:]     dockerOptions  no  ''     dockerVolumeBind  no  [:]       dockerImage  Name of the docker image that should be used. If empty, Docker is not used.  dockerEnvVars  Environment variables to set in the container, e.g. [http_proxy:'proxy:8080']  dockerOptions  Docker options to be set when starting the container. It can be a list or a string.  dockerVolumeBind  Volumes that should be mounted into the container.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/dockerExecute/#step-configuration", 
            "text": "None", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/dockerExecute/#exceptions", 
            "text": "None", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/dockerExecute/#example", 
            "text": "dockerExecute ( dockerImage:   maven:3.5-jdk-7 ){ \n     sh   mvn clean install  }", 
            "title": "Example"
        }, 
        {
            "location": "/steps/durationMeasure/", 
            "text": "durationMeasure\n\n\nDescription\n\n\nThis step is used to measure the duration of a set of steps, e.g. a certain stage.\nThe duration is stored in a Map. The measurement data can then be written to an Influx database using step \ninfluxWriteData\n.\n\n\n\n\nTip\n\n\nMeasuring for example the duration of pipeline stages helps to identify potential bottlenecks within the deployment pipeline.\nThis then helps to counter identified issues with respective optimization measures, e.g parallelization of tests.\n\n\n\n\nPrerequisites\n\n\nnone\n\n\nPipeline configuration\n\n\nnone\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nno\n\n\nempty \nglobalPipelineEnvironment\n\n\n\n\n\n\n\n\nmeasurementName\n\n\nno\n\n\ntest_duration\n\n\n\n\n\n\n\n\n\n\nDetails:\n\n\n\n\nscript\n defines the global script environment of the Jenkinsfile run. Typically \nthis\n is passed to this parameter. This allows the function to access the \ncommonPipelineEnvironment\n for storing the measured duration.\n\n\nmeasurementName\n defines the name of the measurement which is written to the Influx database.\n\n\n\n\nStep configuration\n\n\nnone\n\n\nExample\n\n\ndurationMeasure\n \n(\nscript:\n \nthis\n,\n \nmeasurementName:\n \nbuild_duration\n)\n \n{\n\n    \n//execute your build\n\n\n}", 
            "title": "durationMeasure"
        }, 
        {
            "location": "/steps/durationMeasure/#durationmeasure", 
            "text": "", 
            "title": "durationMeasure"
        }, 
        {
            "location": "/steps/durationMeasure/#description", 
            "text": "This step is used to measure the duration of a set of steps, e.g. a certain stage.\nThe duration is stored in a Map. The measurement data can then be written to an Influx database using step  influxWriteData .   Tip  Measuring for example the duration of pipeline stages helps to identify potential bottlenecks within the deployment pipeline.\nThis then helps to counter identified issues with respective optimization measures, e.g parallelization of tests.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/durationMeasure/#prerequisites", 
            "text": "none", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/durationMeasure/#pipeline-configuration", 
            "text": "none", 
            "title": "Pipeline configuration"
        }, 
        {
            "location": "/steps/durationMeasure/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  no  empty  globalPipelineEnvironment     measurementName  no  test_duration      Details:   script  defines the global script environment of the Jenkinsfile run. Typically  this  is passed to this parameter. This allows the function to access the  commonPipelineEnvironment  for storing the measured duration.  measurementName  defines the name of the measurement which is written to the Influx database.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/durationMeasure/#step-configuration", 
            "text": "none", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/durationMeasure/#example", 
            "text": "durationMeasure   ( script:   this ,   measurementName:   build_duration )   { \n     //execute your build  }", 
            "title": "Example"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/", 
            "text": "handlePipelineStepErrors\n\n\nDescription\n\n\nUsed by other steps to make error analysis easier. Lists parameters and other data available to the step in which the error occurs.\n\n\nPrerequisites\n\n\nnone\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nstepParameters\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nstepName\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nechoDetails\n\n\nyes\n\n\ntrue\n\n\ntrue, false\n\n\n\n\n\n\n\n\n\n\nstepParameters\n - The parameters from the step to be executed. The list of parameters is then shown in the console output.\n\n\nstepName\n - The name of the step executed to be shown in the console output.\n\n\nechoDetails\n - If set to true the following will be output to the console:\n\n\nStep beginning: \n--- BEGIN LIBRARY STEP: ${stepName}.groovy ---\n\n\nStep end: \n--- END LIBRARY STEP: ${stepName}.groovy ---\n\n\nStep errors: \n\n----------------------------------------------------------\n--- ERROR OCCURED IN LIBRARY STEP: ${stepName}\n----------------------------------------------------------\nFOLLOWING PARAMETERS WERE AVAILABLE TO THIS STEP:\n***\n${stepParameters}\n***\nERROR WAS:\n***\n${err}\n***\nFURTHER INFORMATION:\n* Documentation of step ${stepName}: .../${stepName}/\n* Pipeline documentation: https://...\n* GitHub repository for pipeline steps: https://...\n----------------------------------------------------------\n\n\n\n\n\n\n\n\n\nStep configuration\n\n\nnone\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone\n\n\nExample\n\n\nhandlePipelineStepErrors\n \n(\nstepName:\n \nexecuteHealthCheck\n,\n \nstepParameters:\n \nparameters\n)\n \n{\n\n  \ndef\n \nurl\n \n=\n \nnew\n \nUtils\n().\ngetMandatoryParameter\n(\nparameters\n,\n \nurl\n,\n \nnull\n)\n\n  \ndef\n \nstatusCode\n \n=\n \ncurl\n(\nurl\n)\n\n  \nif\n \n(\nstatusCode\n \n!=\n \n200\n)\n\n    \nerror\n \nHealth Check failed: ${statusCode}\n\n\n}", 
            "title": "handlePipelineStepErrors"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#handlepipelinesteperrors", 
            "text": "", 
            "title": "handlePipelineStepErrors"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#description", 
            "text": "Used by other steps to make error analysis easier. Lists parameters and other data available to the step in which the error occurs.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#prerequisites", 
            "text": "none", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#parameters", 
            "text": "parameter  mandatory  default  possible values      stepParameters  yes      stepName  yes      echoDetails  yes  true  true, false      stepParameters  - The parameters from the step to be executed. The list of parameters is then shown in the console output.  stepName  - The name of the step executed to be shown in the console output.  echoDetails  - If set to true the following will be output to the console:  Step beginning:  --- BEGIN LIBRARY STEP: ${stepName}.groovy ---  Step end:  --- END LIBRARY STEP: ${stepName}.groovy ---  Step errors:  ----------------------------------------------------------\n--- ERROR OCCURED IN LIBRARY STEP: ${stepName}\n----------------------------------------------------------\nFOLLOWING PARAMETERS WERE AVAILABLE TO THIS STEP:\n***\n${stepParameters}\n***\nERROR WAS:\n***\n${err}\n***\nFURTHER INFORMATION:\n* Documentation of step ${stepName}: .../${stepName}/\n* Pipeline documentation: https://...\n* GitHub repository for pipeline steps: https://...\n----------------------------------------------------------", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#step-configuration", 
            "text": "none", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#return-value", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#side-effects", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#exceptions", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/handlePipelineStepErrors/#example", 
            "text": "handlePipelineStepErrors   ( stepName:   executeHealthCheck ,   stepParameters:   parameters )   { \n   def   url   =   new   Utils (). getMandatoryParameter ( parameters ,   url ,   null ) \n   def   statusCode   =   curl ( url ) \n   if   ( statusCode   !=   200 ) \n     error   Health Check failed: ${statusCode}  }", 
            "title": "Example"
        }, 
        {
            "location": "/steps/influxWriteData/", 
            "text": "influxWriteData\n\n\nDescription\n\n\nSince your Continuous Delivery Pipeline in Jenkins provides your productive development and delivery infrastructure you should monitor the pipeline to ensure it runs as expected. How to setup this monitoring is described in the following.\n\n\nYou basically need three components:\n\n\n\n\nThe \nInfluxDB Jenkins plugin\n which allows you to send build metrics to InfluxDB servers\n\n\nThe \nInfluxDB\n to store this data (Docker available)\n\n\nA \nGrafana\n dashboard to visualize the data stored in InfluxDB (Docker available)\n\n\n\n\n\n\nno InfluxDB available?\n\n\nIf you don't have an InfluxDB available yet this step will still provide you some benefit.\n\n\nIt will create following files for you and archive them into your build:\n\n\n\n\njenkins_data.json\n: This file gives you build-specific information, like e.g. build result, stage where the build failed\n\n\npipeline_data.json\n: This file gives you detailed information about your pipeline, e.g. stage durations, steps executed, ...\n\n\n\n\n\n\nPrerequisites\n\n\nSetting up InfluxDB with Grafana\n\n\nThe easiest way to start with is using the available official docker images.\nYou can either run these docker containers on the same host on which you run your Jenkins or each docker on individual VMs (hosts).\nVery basic setup can be done like that (with user \"admin\" and password \"adminPwd\" for both InfluxDB and Grafana):\n\n\ndocker run -d -p 8083:8083 -p 8086:8086 --restart=always --name influxdb -v /var/influx_data:/var/lib/influxdb influxdb\ndocker run -d -p 3000:3000 --name grafana --restart=always --link influxdb:influxdb -e \nGF_SECURITY_ADMIN_PASSWORD=adminPwd\n grafana/grafana\n\n\n\n\n\nFor more advanced setup please reach out to the respective documentation:\n\n\n\n\nhttps://hub.docker.com/_/influxdb/ (and https://github.com/docker-library/docs/tree/master/influxdb)\n\n\nhttps://hub.docker.com/r/grafana/grafana/ (and https://github.com/grafana/grafana-docker)\n\n\n\n\nAfter you have started your InfluxDB docker you need to create a database:\n\n\n\n\nin a Webbrowser open the InfluxDB Web-UI using the following URL: \nhost of your docker\n:8083 (port 8083 is used for access via Web-UI, for Jenkins you use port 8086 to access the DB)\n\n\ncreate new DB (the name of this DB you need to provide later to Jenkins)\n\n\ncreate Admin user (this user you need to provide later to Jenkins)\n\n\n\n\n\n\nWith InfluxDB version 1.1 the InfluxDB Web-UI is deprecated\n\n\n\n\nYou can perform the above steps via commandline:\n\n\n\n\n\n\nThe following command will create a database with name \ndatabasename\n\n\n`curl -i -XPOST http://localhost:8086/query --data-urlencode \nq=CREATE DATABASE \\\ndatabasename\\\n`\n\n\n\n\n\n\n\n\n\nThe admin user with the name \nadminusername\n and the password \nadminuserpwd\n can be created with\n\n\n`curl -i -XPOST http://localhost:8086/query --data-urlencode \nq=CREATE USER \\\nadminusername\\\n WITH PASSWORD \n\\\nadminuserpwd\\\n WITH ALL PRIVILEGES\n`\n\n\n\n\n\n\n\n\n\nOnce you have started both docker containers and Influx and Grafana are running you need to configure the Jenkins Plugin according to your settings.\n\n\nPipeline configuration\n\n\nTo setup your Jenkins you need to do two configuration steps:\n\n\n\n\nConfigure Jenkins (via Manage Jenkins)\n\n\nAdapt pipeline configuration\n\n\n\n\nConfigure Jenkins\n\n\nOnce the plugin is available in your Jenkins:\n\n\n\n\ngo to \"Manage Jenkins\" \n \"Configure System\" \n scroll down to section \"influxdb target\"\n\n\nmaintain Influx data\n\n\n\n\n\n\nJenkins as a Service\n\n\nFor Jenkins as a Service instances this is already preset to the local InfluxDB with the name \njenkins\n. In this case there is not need to do any additional configuration.\n\n\n\n\nAdapt pipeline configuration\n\n\nYou need to define the influxDB server in your pipeline as it is defined in the InfluxDb plugin configuration (see above).\n\n\ninfluxDBServer\n=\njenkins\n\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nno\n\n\nempty \ncommonPipelineEnvironment\n\n\n\n\n\n\n\n\nartifactVersion\n\n\nyes\n\n\ncommonPipelineEnvironment.getArtifactVersion()\n\n\n\n\n\n\n\n\ninfluxServer\n\n\nno\n\n\njenkins\n\n\n\n\n\n\n\n\ninfluxPrefix\n\n\nno\n\n\nnull\n\n\n\n\n\n\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\ninfluxServer\n\n\ninfluxPrefix\n\n\n\n\nExample\n\n\ninfluxWriteData\n \nscript:\n \nthis\n\n\n\n\n\nWork with InfluxDB and Grafana\n\n\nYou can access your \nGrafana\n via Web-UI: \nhost of your grafana(-docker)\n:\nport3000\n\n(or another port in case you have defined another one when starting your docker)\n\n\nAs a first step you need to add your InfluxDB as Data source to your Grafana:\n- Login as user admin (PW as defined when starting your docker)\n- in the navigation go to data sources -\n add data source:\n  - name\n  - type: InfluxDB\n  - Url: \\http://\nhost of your InfluxDB server\n:\nport\n\n  - Access: direct (not via proxy)\n  - database: \nname of the DB as specified above\n\n  - User: \nname of the admin user as specified in step above\n\n  - Password: \npassword of the admin user as specified in step above\n\n\n\n\nJenkins as a Service\n\n\nFor Jenkins as a Service the data source configuration is already available.\n\n\nTherefore no need to go through the data source configuration step unless you want to add addtional data sources.\n\n\n\n\nData collected in InfluxDB\n\n\nThe Influx plugin collects following data in the Piper context:\n\n\n\n\nAll data as per default \nInfluxDB plugin capabilities\n\n\nAdditional data collected via \ncommonPipelineEnvironment.setInfluxCustomDataProperty()\n and via \ncommonPipelineEnvironment.setPipelineMeasurement()\n\n\n\n\n\n\nAdd custom information to your InfluxDB\n\n\nYou can simply add custom data collected during your pipeline runs via available data objects.\nExample:\n\n\n//add data to measurement jenkins_custom_data - value can be a String or a Number\n\n\ncommonPipelineEnvironment\n.\nsetInfluxCustomDataProperty\n(\nmyProperty\n,\n \n2018\n)\n\n\n\n\n\n\n\nCollected InfluxDB measurements\n\n\nMeasurements are potentially pre-fixed - see parameter \ninfluxPrefix\n above.\n\n\n\n\n\n\n\n\nMeasurement name\n\n\ndata column\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nAll measurements\n\n\nbuild_number\nproject_name\n\n\nAll below measurements will have these columns. \nDetails see \nInfluxDB plugin documentation\n\n\n\n\n\n\njenkins_data\n\n\nbuild_result\nbuild_time\nlast_successful_build\ntests_failed\ntests_skipped\ntests_total\n...\n\n\nDetails see \nInfluxDB plugin documentation\n\n\n\n\n\n\ncobertura_data\n\n\ncobertura_branch_coverage_rate\ncobertura_class_coverage_rate\ncobertura_line_coverage_rate\ncobertura_package_coverage_rate\n...\n\n\nDetails see \nInfluxDB plugin documentation\n\n\n\n\n\n\njacoco_data\n\n\njacoco_branch_coverage_rate\njacoco_class_coverage_rate\njacoco_instruction_coverage_rate\njacoco_line_coverage_rate\njacoco_method_coverage_rate\n\n\nDetails see \nInfluxDB plugin documentation\n\n\n\n\n\n\nperformance_data\n\n\n90Percentile\naverage\nmax\nmedian\nmin\nerror_count\nerror_percent\n...\n\n\nDetails see \nInfluxDB plugin documentation\n\n\n\n\n\n\nsonarqube_data\n\n\nblocker_issues\ncritical_issues\ninfo_issues\nmajor_issues\nminor_issues\nlines_of_code\n...\n\n\nDetails see \nInfluxDB plugin documentation\n\n\n\n\n\n\njenkins_custom_data\n\n\nPiper fills following colums by default: \nbuild_result\nbuild_result_key\nbuild_step (-\nstep in case of error)\nbuild_error (-\nerror message in case of error)\n\n\nfilled by \ncommonPipelineEnvironment.setInfluxCustomDataProperty()\n\n\n\n\n\n\npipeline_data\n\n\nExamples from the Piper templates:\nbuild_duration\nopa_duration\ndeploy_test_duration\ndeploy_test_duration\nfortify_duration\nrelease_duration\n...\n\n\nfilled by step \nmeasureDuration\n using parameter \nmeasurementName\n\n\n\n\n\n\nstep_data\n\n\nConsidered, e.g.:\nbuild_quality (Milestone/Release)\nbuild_url\nbats\ncheckmarx\nfortify\ngauge\nnsp\nopa\nopensourcedependency\nppms\njmeter\nsupa\nsnyk\nsonar\nsourceclear\nuiveri5\nvulas\nwhitesource\ntraceability\n...\nxmakestage\nxmakepromote\n\n\nfilled by \ncommonPipelineEnvironment.setInfluxStepData()\n\n\n\n\n\n\n\n\nExamples for InfluxDB queries which can be used in Grafana\n\n\n\n\nProject Names containing dashes (-)\n\n\nThe InfluxDB plugin replaces dashes (-) with underscores (_).\n\n\nPlease keep this in mind when specifying your project_name for a InfluxDB query.\n\n\n\n\nExample 1: Select last 10 successful builds\n\n\nselect top(build_number,10), build_result from jenkins_data WHERE build_result = \nSUCCESS\n\n\n\n\n\nExample 2: Select last 10 step names of failed builds\n\n\nselect top(build_number,10), build_result, build_step from jenkins_custom_data WHERE build_result = \nFAILURE\n\n\n\n\n\nExample 3: Select build duration of step for a specific project\n\n\nselect build_duration / 1000 from \npipeline_data\n WHERE project_name=\nPiperTestOrg_piper_test_master\n\n\n\n\n\nExample 4: Get transparency about successful/failed steps for a specific project\n\n\nselect top(build_number,10) AS \nBuild\n, build_url, build_quality, fortify, gauge, vulas, opa from step_data WHERE project_name=\nPiperTestOrg_piper_test_master\n\n\n\n\n\n\n\nNote\n\n\nWith this query you can create transparency about which steps ran successfully / not successfully in your pipeline and which ones were not executed at all.\n\n\nBy specifying all the steps you consider relevant in your select statement it is very easy to create this transparency.", 
            "title": "influxWriteData"
        }, 
        {
            "location": "/steps/influxWriteData/#influxwritedata", 
            "text": "", 
            "title": "influxWriteData"
        }, 
        {
            "location": "/steps/influxWriteData/#description", 
            "text": "Since your Continuous Delivery Pipeline in Jenkins provides your productive development and delivery infrastructure you should monitor the pipeline to ensure it runs as expected. How to setup this monitoring is described in the following.  You basically need three components:   The  InfluxDB Jenkins plugin  which allows you to send build metrics to InfluxDB servers  The  InfluxDB  to store this data (Docker available)  A  Grafana  dashboard to visualize the data stored in InfluxDB (Docker available)    no InfluxDB available?  If you don't have an InfluxDB available yet this step will still provide you some benefit.  It will create following files for you and archive them into your build:   jenkins_data.json : This file gives you build-specific information, like e.g. build result, stage where the build failed  pipeline_data.json : This file gives you detailed information about your pipeline, e.g. stage durations, steps executed, ...", 
            "title": "Description"
        }, 
        {
            "location": "/steps/influxWriteData/#prerequisites", 
            "text": "", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/influxWriteData/#setting-up-influxdb-with-grafana", 
            "text": "The easiest way to start with is using the available official docker images.\nYou can either run these docker containers on the same host on which you run your Jenkins or each docker on individual VMs (hosts).\nVery basic setup can be done like that (with user \"admin\" and password \"adminPwd\" for both InfluxDB and Grafana):  docker run -d -p 8083:8083 -p 8086:8086 --restart=always --name influxdb -v /var/influx_data:/var/lib/influxdb influxdb\ndocker run -d -p 3000:3000 --name grafana --restart=always --link influxdb:influxdb -e  GF_SECURITY_ADMIN_PASSWORD=adminPwd  grafana/grafana  For more advanced setup please reach out to the respective documentation:   https://hub.docker.com/_/influxdb/ (and https://github.com/docker-library/docs/tree/master/influxdb)  https://hub.docker.com/r/grafana/grafana/ (and https://github.com/grafana/grafana-docker)   After you have started your InfluxDB docker you need to create a database:   in a Webbrowser open the InfluxDB Web-UI using the following URL:  host of your docker :8083 (port 8083 is used for access via Web-UI, for Jenkins you use port 8086 to access the DB)  create new DB (the name of this DB you need to provide later to Jenkins)  create Admin user (this user you need to provide later to Jenkins)    With InfluxDB version 1.1 the InfluxDB Web-UI is deprecated   You can perform the above steps via commandline:    The following command will create a database with name  databasename  `curl -i -XPOST http://localhost:8086/query --data-urlencode  q=CREATE DATABASE \\ databasename\\ `    The admin user with the name  adminusername  and the password  adminuserpwd  can be created with  `curl -i -XPOST http://localhost:8086/query --data-urlencode  q=CREATE USER \\ adminusername\\  WITH PASSWORD  \\ adminuserpwd\\  WITH ALL PRIVILEGES `    Once you have started both docker containers and Influx and Grafana are running you need to configure the Jenkins Plugin according to your settings.", 
            "title": "Setting up InfluxDB with Grafana"
        }, 
        {
            "location": "/steps/influxWriteData/#pipeline-configuration", 
            "text": "To setup your Jenkins you need to do two configuration steps:   Configure Jenkins (via Manage Jenkins)  Adapt pipeline configuration", 
            "title": "Pipeline configuration"
        }, 
        {
            "location": "/steps/influxWriteData/#configure-jenkins", 
            "text": "Once the plugin is available in your Jenkins:   go to \"Manage Jenkins\"   \"Configure System\"   scroll down to section \"influxdb target\"  maintain Influx data    Jenkins as a Service  For Jenkins as a Service instances this is already preset to the local InfluxDB with the name  jenkins . In this case there is not need to do any additional configuration.", 
            "title": "Configure Jenkins"
        }, 
        {
            "location": "/steps/influxWriteData/#adapt-pipeline-configuration", 
            "text": "You need to define the influxDB server in your pipeline as it is defined in the InfluxDb plugin configuration (see above).  influxDBServer = jenkins", 
            "title": "Adapt pipeline configuration"
        }, 
        {
            "location": "/steps/influxWriteData/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  no  empty  commonPipelineEnvironment     artifactVersion  yes  commonPipelineEnvironment.getArtifactVersion()     influxServer  no  jenkins     influxPrefix  no  null", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/influxWriteData/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   influxServer  influxPrefix", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/influxWriteData/#example", 
            "text": "influxWriteData   script:   this", 
            "title": "Example"
        }, 
        {
            "location": "/steps/influxWriteData/#work-with-influxdb-and-grafana", 
            "text": "You can access your  Grafana  via Web-UI:  host of your grafana(-docker) : port3000 \n(or another port in case you have defined another one when starting your docker)  As a first step you need to add your InfluxDB as Data source to your Grafana:\n- Login as user admin (PW as defined when starting your docker)\n- in the navigation go to data sources -  add data source:\n  - name\n  - type: InfluxDB\n  - Url: \\http:// host of your InfluxDB server : port \n  - Access: direct (not via proxy)\n  - database:  name of the DB as specified above \n  - User:  name of the admin user as specified in step above \n  - Password:  password of the admin user as specified in step above   Jenkins as a Service  For Jenkins as a Service the data source configuration is already available.  Therefore no need to go through the data source configuration step unless you want to add addtional data sources.", 
            "title": "Work with InfluxDB and Grafana"
        }, 
        {
            "location": "/steps/influxWriteData/#data-collected-in-influxdb", 
            "text": "The Influx plugin collects following data in the Piper context:   All data as per default  InfluxDB plugin capabilities  Additional data collected via  commonPipelineEnvironment.setInfluxCustomDataProperty()  and via  commonPipelineEnvironment.setPipelineMeasurement()    Add custom information to your InfluxDB  You can simply add custom data collected during your pipeline runs via available data objects.\nExample:  //add data to measurement jenkins_custom_data - value can be a String or a Number  commonPipelineEnvironment . setInfluxCustomDataProperty ( myProperty ,   2018 )", 
            "title": "Data collected in InfluxDB"
        }, 
        {
            "location": "/steps/influxWriteData/#collected-influxdb-measurements", 
            "text": "Measurements are potentially pre-fixed - see parameter  influxPrefix  above.     Measurement name  data column  description      All measurements  build_number project_name  All below measurements will have these columns.  Details see  InfluxDB plugin documentation    jenkins_data  build_result build_time last_successful_build tests_failed tests_skipped tests_total ...  Details see  InfluxDB plugin documentation    cobertura_data  cobertura_branch_coverage_rate cobertura_class_coverage_rate cobertura_line_coverage_rate cobertura_package_coverage_rate ...  Details see  InfluxDB plugin documentation    jacoco_data  jacoco_branch_coverage_rate jacoco_class_coverage_rate jacoco_instruction_coverage_rate jacoco_line_coverage_rate jacoco_method_coverage_rate  Details see  InfluxDB plugin documentation    performance_data  90Percentile average max median min error_count error_percent ...  Details see  InfluxDB plugin documentation    sonarqube_data  blocker_issues critical_issues info_issues major_issues minor_issues lines_of_code ...  Details see  InfluxDB plugin documentation    jenkins_custom_data  Piper fills following colums by default:  build_result build_result_key build_step (- step in case of error) build_error (- error message in case of error)  filled by  commonPipelineEnvironment.setInfluxCustomDataProperty()    pipeline_data  Examples from the Piper templates: build_duration opa_duration deploy_test_duration deploy_test_duration fortify_duration release_duration ...  filled by step  measureDuration  using parameter  measurementName    step_data  Considered, e.g.: build_quality (Milestone/Release) build_url bats checkmarx fortify gauge nsp opa opensourcedependency ppms jmeter supa snyk sonar sourceclear uiveri5 vulas whitesource traceability ... xmakestage xmakepromote  filled by  commonPipelineEnvironment.setInfluxStepData()", 
            "title": "Collected InfluxDB measurements"
        }, 
        {
            "location": "/steps/influxWriteData/#examples-for-influxdb-queries-which-can-be-used-in-grafana", 
            "text": "Project Names containing dashes (-)  The InfluxDB plugin replaces dashes (-) with underscores (_).  Please keep this in mind when specifying your project_name for a InfluxDB query.", 
            "title": "Examples for InfluxDB queries which can be used in Grafana"
        }, 
        {
            "location": "/steps/influxWriteData/#example-1-select-last-10-successful-builds", 
            "text": "select top(build_number,10), build_result from jenkins_data WHERE build_result =  SUCCESS", 
            "title": "Example 1: Select last 10 successful builds"
        }, 
        {
            "location": "/steps/influxWriteData/#example-2-select-last-10-step-names-of-failed-builds", 
            "text": "select top(build_number,10), build_result, build_step from jenkins_custom_data WHERE build_result =  FAILURE", 
            "title": "Example 2: Select last 10 step names of failed builds"
        }, 
        {
            "location": "/steps/influxWriteData/#example-3-select-build-duration-of-step-for-a-specific-project", 
            "text": "select build_duration / 1000 from  pipeline_data  WHERE project_name= PiperTestOrg_piper_test_master", 
            "title": "Example 3: Select build duration of step for a specific project"
        }, 
        {
            "location": "/steps/influxWriteData/#example-4-get-transparency-about-successfulfailed-steps-for-a-specific-project", 
            "text": "select top(build_number,10) AS  Build , build_url, build_quality, fortify, gauge, vulas, opa from step_data WHERE project_name= PiperTestOrg_piper_test_master    Note  With this query you can create transparency about which steps ran successfully / not successfully in your pipeline and which ones were not executed at all.  By specifying all the steps you consider relevant in your select statement it is very easy to create this transparency.", 
            "title": "Example 4: Get transparency about successful/failed steps for a specific project"
        }, 
        {
            "location": "/steps/mavenExecute/", 
            "text": "mavenExecute\n\n\nDescription\n\n\nExecutes a maven command inside a Docker container.\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\nexample values\n\n\n\n\n\n\n\n\n\n\ndockerImage\n\n\nno\n\n\n'maven:3.5-jdk-7'\n\n\n\n\n\n\n\n\nglobalSettingsFile\n\n\nno\n\n\n\n\n'local_folder/settings.xml'\n\n\n\n\n\n\nprojectSettingsFile\n\n\nno\n\n\n\n\n\n\n\n\n\n\npomPath\n\n\nno\n\n\n\n\n'local_folder/m2'\n\n\n\n\n\n\nflags\n\n\nno\n\n\n\n\n'-o'\n\n\n\n\n\n\ngoals\n\n\nno\n\n\n\n\n'clean install'\n\n\n\n\n\n\nm2Path\n\n\nno\n\n\n\n\n'local_folder/m2'\n\n\n\n\n\n\ndefines\n\n\nno\n\n\n\n\n'-Dmaven.tests.skip=true'\n\n\n\n\n\n\nlogSuccessfulMavenTransfers\n\n\nno\n\n\nfalse\n\n\n'true'\n\n\n\n\n\n\n\n\n\n\ndockerImage\n Name of the docker image that should be used.\n\n\nglobalSettingsFile\n Path or url to the mvn settings file that should be used as global settings file. \n\n\nprojectSettingsFile\n Path or url to the mvn settings file that should be used as project settings file.\n\n\npomPath\n Path to the pom file that should be used.\n\n\nflags\n Flags to provide when running mvn.\n\n\ngoals\n Maven goals that should be executed.\n\n\nm2Path\n Path to the location of the local repository that should be used.\n\n\ndefines\n Additional properties.\n\n\nlogSuccessfulMavenTransfers\n configures maven to log successful downloads. This is set to \nfalse\n by default to reduce the noise in build logs.\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\ndockerImage\n\n\nglobalSettingsFile\n\n\nprojectSettingsFile\n\n\npomPath\n\n\nm2Path\n\n\n\n\nExceptions\n\n\nNone\n\n\nExample\n\n\nmavenExecute\n \nscript:\n \nthis\n,\n \ngoals:\n \nclean install", 
            "title": "mavenExecute"
        }, 
        {
            "location": "/steps/mavenExecute/#mavenexecute", 
            "text": "", 
            "title": "mavenExecute"
        }, 
        {
            "location": "/steps/mavenExecute/#description", 
            "text": "Executes a maven command inside a Docker container.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/mavenExecute/#parameters", 
            "text": "parameter  mandatory  default  example values      dockerImage  no  'maven:3.5-jdk-7'     globalSettingsFile  no   'local_folder/settings.xml'    projectSettingsFile  no      pomPath  no   'local_folder/m2'    flags  no   '-o'    goals  no   'clean install'    m2Path  no   'local_folder/m2'    defines  no   '-Dmaven.tests.skip=true'    logSuccessfulMavenTransfers  no  false  'true'      dockerImage  Name of the docker image that should be used.  globalSettingsFile  Path or url to the mvn settings file that should be used as global settings file.   projectSettingsFile  Path or url to the mvn settings file that should be used as project settings file.  pomPath  Path to the pom file that should be used.  flags  Flags to provide when running mvn.  goals  Maven goals that should be executed.  m2Path  Path to the location of the local repository that should be used.  defines  Additional properties.  logSuccessfulMavenTransfers  configures maven to log successful downloads. This is set to  false  by default to reduce the noise in build logs.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/mavenExecute/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   dockerImage  globalSettingsFile  projectSettingsFile  pomPath  m2Path", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/mavenExecute/#exceptions", 
            "text": "None", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/mavenExecute/#example", 
            "text": "mavenExecute   script:   this ,   goals:   clean install", 
            "title": "Example"
        }, 
        {
            "location": "/steps/mtaBuild/", 
            "text": "mtaBuild\n\n\nDescription\n\n\nExecutes the SAP Multitarget Application Archive Builder to create an mtar archive of the application.\n\n\nBefore doing this, validates that SAP Multitarget Application Archive Builder exists and the version is compatible.\n\n\nNote that a version is formed by \nmajor.minor.patch\n, and a version is compatible to another version if the minor and patch versions are higher, but the major version is not, e.g. if 3.39.10 is the expected version, 3.39.11 and 3.40.1 would be compatible versions, but 4.0.1 would not be a compatible version.\n\n\nPrerequisites\n\n\n\n\nSAP MTA Archive Builder 1.0.6 or compatible version\n - can be downloaded from \nSAP Development Tools\n.\n\n\nJava 8 or compatible version\n - necessary to run the \nmta.jar\n file.\n\n\nNodeJS installed\n - the MTA Builder uses \nnpm\n to download node module dependencies such as \ngrunt\n.\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nbuildTarget\n\n\nyes\n\n\n'NEO'\n\n\n'CF', 'NEO', 'XSA'\n\n\n\n\n\n\nextension\n\n\nno\n\n\n\n\n\n\n\n\n\n\nmtaJarLocation\n\n\nno\n\n\n'mta.jar'\n\n\n\n\n\n\n\n\napplicationName\n\n\nno\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscript\n - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the \nthis\n parameter, as in \nscript: this\n. This allows the function to access the \ncommonPipelineEnvironment\n for retrieving, for example, configuration parameters.\n\n\nbuildTarget\n - The target platform to which the mtar can be deployed.\n\n\nextension\n - The path to the extension descriptor file.\n\n\nmtaJarLocation\n - The location of the SAP Multitarget Application Archive Builder jar file, including file name and extension. First, the location is retrieved from the environment variables using the environment variable\nMTA_JAR_LOCATION\n. If no environment variable is provided, the location is retrieved from the parameters, or the step configuration using the key \nmtaJarLocation\n. If SAP Multitarget Application Archive Builder is not found on one of the previous locations an AbortException is thrown.\nNote that the environment variable \nMTA_JAR_LOCATION\n has priority. In case that the script runs on multiple nodes, SAP Multitarget Application Archive Builder must be located on all the nodes, therefore the environment variable must be also configured on all the nodes.\n\n\napplicationName\n - The name of the application which is being built. If the parameter has been provided and no \nmta.yaml\n exists, the \nmta.yaml\n will be automatically generated using this parameter and the information (\nname\n and \nversion\n) from \npackage.json\n before the actual build starts.\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\nbuildTarget\n\n\nextension\n\n\nmtaJarLocation\n\n\napplicationName\n\n\n\n\nReturn value\n\n\nThe file name of the resulting archive is returned with this step. The file name is extracted from the key \nID\n defined in \nmta.yaml\n.\n\n\nSide effects\n\n\n\n\nThe file name of the resulting archive is written to the \ncommonPipelineEnvironment\n with variable name \nmtarFileName\n.\n\n\n\n\nExceptions\n\n\n\n\nAbortException\n:\n\n\nIf SAP Multitarget Application Archive Builder is not found.\n\n\nIf there is an invalid \nbuildTarget\n.\n\n\nIf there is no key \nID\n inside the \nmta.yaml\n file.\n\n\n\n\n\n\n\n\nExample\n\n\ndef\n \nmtarFileName\n\n\ndir\n(\n/path/to/FioriApp\n){\n\n  \nmtarFileName\n \n=\n \nmtaBuild\n \nscript:\nthis\n,\n \nbuildTarget:\n \nNEO\n\n\n}", 
            "title": "mtaBuild"
        }, 
        {
            "location": "/steps/mtaBuild/#mtabuild", 
            "text": "", 
            "title": "mtaBuild"
        }, 
        {
            "location": "/steps/mtaBuild/#description", 
            "text": "Executes the SAP Multitarget Application Archive Builder to create an mtar archive of the application.  Before doing this, validates that SAP Multitarget Application Archive Builder exists and the version is compatible.  Note that a version is formed by  major.minor.patch , and a version is compatible to another version if the minor and patch versions are higher, but the major version is not, e.g. if 3.39.10 is the expected version, 3.39.11 and 3.40.1 would be compatible versions, but 4.0.1 would not be a compatible version.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/mtaBuild/#prerequisites", 
            "text": "SAP MTA Archive Builder 1.0.6 or compatible version  - can be downloaded from  SAP Development Tools .  Java 8 or compatible version  - necessary to run the  mta.jar  file.  NodeJS installed  - the MTA Builder uses  npm  to download node module dependencies such as  grunt .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/mtaBuild/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  yes      buildTarget  yes  'NEO'  'CF', 'NEO', 'XSA'    extension  no      mtaJarLocation  no  'mta.jar'     applicationName  no        script  - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the  this  parameter, as in  script: this . This allows the function to access the  commonPipelineEnvironment  for retrieving, for example, configuration parameters.  buildTarget  - The target platform to which the mtar can be deployed.  extension  - The path to the extension descriptor file.  mtaJarLocation  - The location of the SAP Multitarget Application Archive Builder jar file, including file name and extension. First, the location is retrieved from the environment variables using the environment variable MTA_JAR_LOCATION . If no environment variable is provided, the location is retrieved from the parameters, or the step configuration using the key  mtaJarLocation . If SAP Multitarget Application Archive Builder is not found on one of the previous locations an AbortException is thrown.\nNote that the environment variable  MTA_JAR_LOCATION  has priority. In case that the script runs on multiple nodes, SAP Multitarget Application Archive Builder must be located on all the nodes, therefore the environment variable must be also configured on all the nodes.  applicationName  - The name of the application which is being built. If the parameter has been provided and no  mta.yaml  exists, the  mta.yaml  will be automatically generated using this parameter and the information ( name  and  version ) from  package.json  before the actual build starts.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/mtaBuild/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   buildTarget  extension  mtaJarLocation  applicationName", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/mtaBuild/#return-value", 
            "text": "The file name of the resulting archive is returned with this step. The file name is extracted from the key  ID  defined in  mta.yaml .", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/mtaBuild/#side-effects", 
            "text": "The file name of the resulting archive is written to the  commonPipelineEnvironment  with variable name  mtarFileName .", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/mtaBuild/#exceptions", 
            "text": "AbortException :  If SAP Multitarget Application Archive Builder is not found.  If there is an invalid  buildTarget .  If there is no key  ID  inside the  mta.yaml  file.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/mtaBuild/#example", 
            "text": "def   mtarFileName  dir ( /path/to/FioriApp ){ \n   mtarFileName   =   mtaBuild   script: this ,   buildTarget:   NEO  }", 
            "title": "Example"
        }, 
        {
            "location": "/steps/neoDeploy/", 
            "text": "neoDeploy\n\n\nDescription\n\n\nDeploys an Application to SAP Cloud Platform (SAP CP) using the SAP Cloud Platform Console Client (Neo Java Web SDK).\n\n\nBefore doing this, validates that SAP Cloud Platform Console Client is installed and the version is compatible.\n\n\nNote that a version is formed by \nmajor.minor.patch\n, and a version is compatible to another version if the minor and patch versions are higher, but the major version is not, e.g. if 3.39.10 is the expected version, 3.39.11 and 3.40.1 would be compatible versions, but 4.0.1 would not be a compatible version.\n\n\nPrerequisites\n\n\n\n\nSAP CP account\n - the account to where the application is deployed.\n\n\nSAP CP user for deployment\n - a user with deployment permissions in the given account.\n\n\nJenkins credentials for deployment\n - must be configured in Jenkins credentials with a dedicated Id.\n\n\n\n\n\n\n\n\n\n\nNeo Java Web SDK 3.39.10 or compatible version\n - can be downloaded from \nMaven Central\n. The Neo Java Web SDK\nneeds to be extracted into the folder provided by \nneoHome\n. In case this parameters is not provided and there is no NEO_HOME parameter in the environment\n\nneoRoot\n/tools\n needs to be in the \nPATH\n. This step is also capable of triggering the neo deploy tool provided inside a docker image.\n\n\n\n\n\n\nJava 8 or compatible version\n - needed by the \nNeo-Java-Web-SDK\n\n\n\n\n\n\nParameters when using MTA deployment method (default - MTA)\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\naccount\n\n\nno\n\n\n\n\n\n\n\n\n\n\narchivePath\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ndeployAccount\n deprecated, use \naccount\n\n\nno\n\n\n\n\n\n\n\n\n\n\ndeployHost\n deprecated, use \nhost\n\n\nno\n\n\n\n\n\n\n\n\n\n\ndeployMode\n\n\nyes\n\n\n'mta'\n\n\n'mta'\n, \n'warParams'\n, \n'warPropertiesFile'\n\n\n\n\n\n\nhost\n\n\nno\n\n\n\n\n\n\n\n\n\n\nneoCredentialsId\n\n\nno\n\n\n'CI_CREDENTIALS_ID'\n\n\n\n\n\n\n\n\nneoHome\n\n\nno\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\nParameters when using WAR file deployment method with .properties file (WAR_PROPERTIESFILE)\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\narchivePath\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ndeployMode\n\n\nyes\n\n\n'mta'\n\n\n'mta'\n, \n'warParams'\n, \n'warPropertiesFile'\n\n\n\n\n\n\nneoCredentialsId\n\n\nno\n\n\n'CI_CREDENTIALS_ID'\n\n\n\n\n\n\n\n\nneoHome\n\n\nno\n\n\n\n\n\n\n\n\n\n\npropertiesFile\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nwarAction\n\n\nyes\n\n\n'deploy'\n\n\n'deploy'\n, \n'rolling-update'\n\n\n\n\n\n\n\n\nParameters when using WAR file deployment method witout .properties file - with parameters (WAR_PARAMS)\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\naccount\n\n\nno\n\n\n\n\n\n\n\n\n\n\napplicationName\n\n\nyes\n\n\n\n\n\n\n\n\n\n\narchivePath\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ndeployAccount\n deprecated, use \naccount\n\n\nno\n\n\n\n\n\n\n\n\n\n\ndeployHost\n deprecated, use \nhost\n\n\nno\n\n\n\n\n\n\n\n\n\n\ndeployMode\n\n\nyes\n\n\n'mta'\n\n\n'mta'\n, \n'warParams'\n, \n'warPropertiesFile'\n\n\n\n\n\n\nhost\n\n\nno\n\n\n\n\n\n\n\n\n\n\nneoCredentialsId\n\n\nno\n\n\n'CI_CREDENTIALS_ID'\n\n\n\n\n\n\n\n\nneoHome\n\n\nno\n\n\n\n\n\n\n\n\n\n\nruntime\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nruntime-version\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nvmSize\n\n\nno\n\n\n'lite'\n\n\n'lite'\n, \n'pro'\n, \n'prem'\n, \n'prem-plus'\n\n\n\n\n\n\nwarAction\n\n\nyes\n\n\n'deploy'\n\n\n'deploy'\n, \n'rolling-update'\n\n\n\n\n\n\n\n\n\n\naccount\n - The SAP Cloud Platform account to deploy to.\n\n\napplicationName\n - Name of the application you want to manage, configure, or deploy\n\n\narchivePath\n- The path to the archive for deployment to SAP CP.\n\n\ndeployAccount\n - deprecated, use \naccount\n. The SAP Cloud Platform account to deploy to.\n\n\ndeployHost\n - deprecated, use \nhost\n. The SAP Cloud Platform host to deploy to.\n\n\ndeployMode\n - The deployment mode which should be used. Available options are \n'mta'\n (default), \n'warParams'\n (deploying WAR file and passing all the deployment parameters via the function call) and \n'warPropertiesFile'\n (deploying WAR file and putting all the deployment parameters in a .properties file)\n\n\nhost\n - The SAP Cloud Platform host to deploy to.\n\n\nneoCredentialsId\n - The Jenkins credentials containing user and password used for SAP CP deployment.\n\n\nneoHome\n - The path to the \nneo-java-web-sdk\n tool used for SAP CP deployment. If no parameter is provided, the path is retrieved from the environment variables using the environment variable \nNEO_HOME\n. If no parameter and no environment variable is provided, the path is retrieved from the step configuration using the step configuration key \nneoHome\n. If the previous configurations are not provided, the tool is expected on the \nPATH\n, and if it is not available on the \nPATH\n an AbortException is thrown.\n\n\npropertiesFile\n - The path to the .properties file in which all necessary deployment properties for the application are defined.\n\n\nruntime\n - Name of SAP Cloud Platform application runtime\n\n\nruntime-version\n - Version of SAP Cloud Platform application runtime\n\n\nscript\n - The common script environment of the Jenkinsfile run. Typically \nthis\n is passed to this parameter. This allows the function to access the \ncommonPipelineEnvironment\n for retrieving e.g. configuration parameters.\n\n\nvmSize\n - Compute unit (VM) size. Acceptable values: lite, pro, prem, prem-plus.\n\n\nwarAction\n - Action mode when using WAR file mode. Available options are \ndeploy\n (default) and \nrolling-update\n which performs update of an application without downtime in one go.\n\n\n\n\nThe step is prepared for being executed in docker. The corresponding parameters can be applied. See step \ndockerExecute\n for details.\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\naccount\n\n\ndockerEnvVars\n\n\ndockerImage\n\n\ndockerOptions\n\n\nhost\n\n\nneoCredentialsId\n\n\nneoHome\n\n\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\n\n\nException\n:\n\n\nIf \narchivePath\n is not provided.\n\n\nIf \npropertiesFile\n is not provided (when using \n'WAR_PROPERTIESFILE'\n deployment mode).\n\n\nIf \napplicationName\n is not provided (when using \n'WAR_PARAMS'\n deployment mode).\n\n\nIf \nruntime\n is not provided (when using \n'WAR_PARAMS'\n deployment mode).\n\n\nIf \nruntime-version\n is not provided (when using \n'WAR_PARAMS'\n deployment mode).\n\n\n\n\n\n\nAbortException\n:\n\n\nIf neo-java-web-sdk is not installed, or \nneoHome\nis wrong.\n\n\nIf \ndeployHost\n is wrong.\n\n\nIf \ndeployAccount\n is wrong.\n\n\n\n\n\n\nCredentialNotFoundException\n:\n\n\nIf the credentials cannot be resolved.\n\n\n\n\n\n\n\n\nExample\n\n\nneoDeploy\n \nscript:\n \nthis\n,\n \narchivePath:\n \npath/to/archiveFile.mtar\n,\n \ncredentialsId:\n \nmy-credentials-id\n\n\n\n\n\nExample configuration:\n\n\nsteps:\n  \n...\n\n  neoDeploy:\n\n        account: \nmyDeployAccount\n\n        host: hana.example.org", 
            "title": "neoDeploy"
        }, 
        {
            "location": "/steps/neoDeploy/#neodeploy", 
            "text": "", 
            "title": "neoDeploy"
        }, 
        {
            "location": "/steps/neoDeploy/#description", 
            "text": "Deploys an Application to SAP Cloud Platform (SAP CP) using the SAP Cloud Platform Console Client (Neo Java Web SDK).  Before doing this, validates that SAP Cloud Platform Console Client is installed and the version is compatible.  Note that a version is formed by  major.minor.patch , and a version is compatible to another version if the minor and patch versions are higher, but the major version is not, e.g. if 3.39.10 is the expected version, 3.39.11 and 3.40.1 would be compatible versions, but 4.0.1 would not be a compatible version.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/neoDeploy/#prerequisites", 
            "text": "SAP CP account  - the account to where the application is deployed.  SAP CP user for deployment  - a user with deployment permissions in the given account.  Jenkins credentials for deployment  - must be configured in Jenkins credentials with a dedicated Id.      Neo Java Web SDK 3.39.10 or compatible version  - can be downloaded from  Maven Central . The Neo Java Web SDK\nneeds to be extracted into the folder provided by  neoHome . In case this parameters is not provided and there is no NEO_HOME parameter in the environment neoRoot /tools  needs to be in the  PATH . This step is also capable of triggering the neo deploy tool provided inside a docker image.    Java 8 or compatible version  - needed by the  Neo-Java-Web-SDK", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/neoDeploy/#parameters-when-using-mta-deployment-method-default-mta", 
            "text": "parameter  mandatory  default  possible values      account  no      archivePath  yes      deployAccount  deprecated, use  account  no      deployHost  deprecated, use  host  no      deployMode  yes  'mta'  'mta' ,  'warParams' ,  'warPropertiesFile'    host  no      neoCredentialsId  no  'CI_CREDENTIALS_ID'     neoHome  no      script  yes", 
            "title": "Parameters when using MTA deployment method (default - MTA)"
        }, 
        {
            "location": "/steps/neoDeploy/#parameters-when-using-war-file-deployment-method-with-properties-file-war_propertiesfile", 
            "text": "parameter  mandatory  default  possible values      archivePath  yes      deployMode  yes  'mta'  'mta' ,  'warParams' ,  'warPropertiesFile'    neoCredentialsId  no  'CI_CREDENTIALS_ID'     neoHome  no      propertiesFile  yes      script  yes      warAction  yes  'deploy'  'deploy' ,  'rolling-update'", 
            "title": "Parameters when using WAR file deployment method with .properties file (WAR_PROPERTIESFILE)"
        }, 
        {
            "location": "/steps/neoDeploy/#parameters-when-using-war-file-deployment-method-witout-properties-file-with-parameters-war_params", 
            "text": "parameter  mandatory  default  possible values      account  no      applicationName  yes      archivePath  yes      deployAccount  deprecated, use  account  no      deployHost  deprecated, use  host  no      deployMode  yes  'mta'  'mta' ,  'warParams' ,  'warPropertiesFile'    host  no      neoCredentialsId  no  'CI_CREDENTIALS_ID'     neoHome  no      runtime  yes      runtime-version  yes      script  yes      vmSize  no  'lite'  'lite' ,  'pro' ,  'prem' ,  'prem-plus'    warAction  yes  'deploy'  'deploy' ,  'rolling-update'      account  - The SAP Cloud Platform account to deploy to.  applicationName  - Name of the application you want to manage, configure, or deploy  archivePath - The path to the archive for deployment to SAP CP.  deployAccount  - deprecated, use  account . The SAP Cloud Platform account to deploy to.  deployHost  - deprecated, use  host . The SAP Cloud Platform host to deploy to.  deployMode  - The deployment mode which should be used. Available options are  'mta'  (default),  'warParams'  (deploying WAR file and passing all the deployment parameters via the function call) and  'warPropertiesFile'  (deploying WAR file and putting all the deployment parameters in a .properties file)  host  - The SAP Cloud Platform host to deploy to.  neoCredentialsId  - The Jenkins credentials containing user and password used for SAP CP deployment.  neoHome  - The path to the  neo-java-web-sdk  tool used for SAP CP deployment. If no parameter is provided, the path is retrieved from the environment variables using the environment variable  NEO_HOME . If no parameter and no environment variable is provided, the path is retrieved from the step configuration using the step configuration key  neoHome . If the previous configurations are not provided, the tool is expected on the  PATH , and if it is not available on the  PATH  an AbortException is thrown.  propertiesFile  - The path to the .properties file in which all necessary deployment properties for the application are defined.  runtime  - Name of SAP Cloud Platform application runtime  runtime-version  - Version of SAP Cloud Platform application runtime  script  - The common script environment of the Jenkinsfile run. Typically  this  is passed to this parameter. This allows the function to access the  commonPipelineEnvironment  for retrieving e.g. configuration parameters.  vmSize  - Compute unit (VM) size. Acceptable values: lite, pro, prem, prem-plus.  warAction  - Action mode when using WAR file mode. Available options are  deploy  (default) and  rolling-update  which performs update of an application without downtime in one go.   The step is prepared for being executed in docker. The corresponding parameters can be applied. See step  dockerExecute  for details.", 
            "title": "Parameters when using WAR file deployment method witout .properties file - with parameters (WAR_PARAMS)"
        }, 
        {
            "location": "/steps/neoDeploy/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   account  dockerEnvVars  dockerImage  dockerOptions  host  neoCredentialsId  neoHome", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/neoDeploy/#return-value", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/neoDeploy/#side-effects", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/neoDeploy/#exceptions", 
            "text": "Exception :  If  archivePath  is not provided.  If  propertiesFile  is not provided (when using  'WAR_PROPERTIESFILE'  deployment mode).  If  applicationName  is not provided (when using  'WAR_PARAMS'  deployment mode).  If  runtime  is not provided (when using  'WAR_PARAMS'  deployment mode).  If  runtime-version  is not provided (when using  'WAR_PARAMS'  deployment mode).    AbortException :  If neo-java-web-sdk is not installed, or  neoHome is wrong.  If  deployHost  is wrong.  If  deployAccount  is wrong.    CredentialNotFoundException :  If the credentials cannot be resolved.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/neoDeploy/#example", 
            "text": "neoDeploy   script:   this ,   archivePath:   path/to/archiveFile.mtar ,   credentialsId:   my-credentials-id   Example configuration:  steps:\n   ... \n  neoDeploy:\n\n        account:  myDeployAccount \n        host: hana.example.org", 
            "title": "Example"
        }, 
        {
            "location": "/steps/pipelineExecute/", 
            "text": "pipelineExecute\n\n\nDescription\n\n\nLoads a pipeline from a git repository. The idea is to set up a pipeline job in Jenkins that loads a minimal pipeline, which in turn loads the shared library and then uses this step to load the actual pipeline.\n\n\nA centrally maintained pipeline script (Jenkinsfile) can be re-used by\nseveral projects using \npipelineExecute\n as outlined in the example\nbelow.\n\n\nPrerequisites\n\n\nnone\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nrepoUrl\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nbranch\n\n\nno\n\n\n'master'\n\n\n\n\n\n\n\n\npath\n\n\nno\n\n\n'Jenkinsfile'\n\n\n\n\n\n\n\n\ncredentialsId\n\n\nno\n\n\nAn empty String\n\n\n\n\n\n\n\n\n\n\n\n\nrepoUrl\n The url to the git repository of the pipeline to be loaded.\n\n\nbranch\n The branch of the git repository from which the pipeline should be checked out.\n\n\npath\n The path to the Jenkinsfile, inside the repository, to be loaded.\n\n\ncredentialsId\n The Jenkins credentials containing user and password needed to access a private git repository.\n\n\n\n\nStep configuration\n\n\nnone\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\n\n\nException\n\n\nIf \nrepoUrl\n is not provided.\n\n\n\n\n\n\n\n\nExample\n\n\npipelineExecute\n \nrepoUrl:\n \nhttps://github.com/MyOrg/MyPipelineRepo.git\n,\n \nbranch:\n \nfeature1\n,\n \npath:\n \npath/to/Jenkinsfile\n,\n \ncredentialsId:\n \nMY_REPO_CREDENTIALS", 
            "title": "pipelineExecute"
        }, 
        {
            "location": "/steps/pipelineExecute/#pipelineexecute", 
            "text": "", 
            "title": "pipelineExecute"
        }, 
        {
            "location": "/steps/pipelineExecute/#description", 
            "text": "Loads a pipeline from a git repository. The idea is to set up a pipeline job in Jenkins that loads a minimal pipeline, which in turn loads the shared library and then uses this step to load the actual pipeline.  A centrally maintained pipeline script (Jenkinsfile) can be re-used by\nseveral projects using  pipelineExecute  as outlined in the example\nbelow.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/pipelineExecute/#prerequisites", 
            "text": "none", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/pipelineExecute/#parameters", 
            "text": "parameter  mandatory  default  possible values      repoUrl  yes      branch  no  'master'     path  no  'Jenkinsfile'     credentialsId  no  An empty String       repoUrl  The url to the git repository of the pipeline to be loaded.  branch  The branch of the git repository from which the pipeline should be checked out.  path  The path to the Jenkinsfile, inside the repository, to be loaded.  credentialsId  The Jenkins credentials containing user and password needed to access a private git repository.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/pipelineExecute/#step-configuration", 
            "text": "none", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/pipelineExecute/#return-value", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/pipelineExecute/#side-effects", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/pipelineExecute/#exceptions", 
            "text": "Exception  If  repoUrl  is not provided.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/pipelineExecute/#example", 
            "text": "pipelineExecute   repoUrl:   https://github.com/MyOrg/MyPipelineRepo.git ,   branch:   feature1 ,   path:   path/to/Jenkinsfile ,   credentialsId:   MY_REPO_CREDENTIALS", 
            "title": "Example"
        }, 
        {
            "location": "/steps/pipelineStashFiles/", 
            "text": "pipelineStashFiles\n\n\nDescription\n\n\nThis step stashes files that are needed in other build steps (on other nodes).\n\n\nPrerequsites\n\n\nnone\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nno\n\n\nempty \ncommonPipelineEnvironment\n\n\n\n\n\n\n\n\nrunCheckmarx\n\n\nno\n\n\nfalse\n\n\n\n\n\n\n\n\nrunOpaTests\n\n\nno\n\n\nfalse\n\n\n\n\n\n\n\n\nstashIncludes\n\n\nno\n\n\nsee details\n\n\n\n\n\n\n\n\nstashExcludes\n\n\nno\n\n\nsee details\n\n\n\n\n\n\n\n\n\n\nDetails:\n\n\nThe step is stashing files before and after the build. This is due to the fact, that some of the code that needs to be stashed, is generated during the build (TypeScript for NPM).\n\n\n\n\n\n\n\n\nstash name\n\n\nmandatory\n\n\nprerequisite\n\n\npattern\n\n\n\n\n\n\n\n\n\n\nbuildDescriptor\n\n\nno\n\n\n\n\nincludes: \n**/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/whitesource_config.py, **/mta*.y*ml, **/.npmrc, **/whitesource.*.json, **/whitesource-fs-agent.config, Dockerfile, **/VERSION, **/version.txt, **/build.sbt, **/sbtDescriptor.json, **/project/*\n excludes: \n**/node_modules/**/package.json\n\n\n\n\n\n\ncheckmarx\n\n\nno\n\n\nCheckmarx is enabled\n\n\nincludes: \n**/*.js, **/*.scala, **/*.go\n excludes: \n**/*.mockserver.js, node_modules/**/*.js\n\n\n\n\n\n\nclassFiles\n\n\nno\n\n\n\n\nincludes: \n**/target/classes/**/*.class, **/target/test-classes/**/*.class\n \nexcludes: \n''\n\n\n\n\n\n\ndeployDescriptor\n\n\nno\n\n\n\n\nincludes: \n**/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml\nexclude: \n''\n\n\n\n\n\n\ngit\n\n\nno\n\n\n\n\nincludes: \n**/gitmetadata/**\nexludes: \n''\n\n\n\n\n\n\nopa5\n\n\nno\n\n\nOPA5 is enabled\n\n\nincludes: \n**/*.*\nexcludes: \n''\n\n\n\n\n\n\nopensourceConfiguration\n\n\nno\n\n\n\n\nincludes: \n**/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk\nexcludes: \n''\n\n\n\n\n\n\npipelineConfigAndTests\n\n\nno\n\n\n\n\nincludes: \n.pipeline/*.*\nexcludes: \n''\n\n\n\n\n\n\nsecurityDescriptor\n\n\nno\n\n\n\n\nincludes: \n**/xs-security.json\nexludes: \n''\n\n\n\n\n\n\nsonar\n\n\nno\n\n\n\n\nincludes: \n**/jacoco*.exec, **/sonar-project.properties\nexludes: \n''\n\n\n\n\n\n\ntests\n\n\nno\n\n\n\n\nincludes: \n**/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js\nexcludes: \n''\n\n\n\n\n\n\n\n\n\n\nOverwriting default stashing behavior\n\n\nIt is possible to overwrite the default behavior of the stashes using the parameters \nstashIncludes\n and \nstashExcludes\n , e.g.\n\n\n\n\nstashIncludes: [buildDescriptor: '**/mybuild.yml]\n\n\nstashExcludes: [tests: '**/NOTRELEVANT.*]\n\n\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\nrunOpaTests\n\n\nrunCheckmarx\n\n\nstashExcludes\n\n\nstashIncludes\n\n\n\n\nExplanation of pipeline step\n\n\nUsage of pipeline step:\n\n\npipelineStashFiles\n \nscript:\n \nthis\n \n{\n\n  \nmavenExecute\n \nscript:\n \nthis\n,\n \n...\n\n\n}", 
            "title": "pipelineStashFiles"
        }, 
        {
            "location": "/steps/pipelineStashFiles/#pipelinestashfiles", 
            "text": "", 
            "title": "pipelineStashFiles"
        }, 
        {
            "location": "/steps/pipelineStashFiles/#description", 
            "text": "This step stashes files that are needed in other build steps (on other nodes).", 
            "title": "Description"
        }, 
        {
            "location": "/steps/pipelineStashFiles/#prerequsites", 
            "text": "none", 
            "title": "Prerequsites"
        }, 
        {
            "location": "/steps/pipelineStashFiles/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  no  empty  commonPipelineEnvironment     runCheckmarx  no  false     runOpaTests  no  false     stashIncludes  no  see details     stashExcludes  no  see details      Details:  The step is stashing files before and after the build. This is due to the fact, that some of the code that needs to be stashed, is generated during the build (TypeScript for NPM).     stash name  mandatory  prerequisite  pattern      buildDescriptor  no   includes:  **/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/whitesource_config.py, **/mta*.y*ml, **/.npmrc, **/whitesource.*.json, **/whitesource-fs-agent.config, Dockerfile, **/VERSION, **/version.txt, **/build.sbt, **/sbtDescriptor.json, **/project/*  excludes:  **/node_modules/**/package.json    checkmarx  no  Checkmarx is enabled  includes:  **/*.js, **/*.scala, **/*.go  excludes:  **/*.mockserver.js, node_modules/**/*.js    classFiles  no   includes:  **/target/classes/**/*.class, **/target/test-classes/**/*.class   excludes:  ''    deployDescriptor  no   includes:  **/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml exclude:  ''    git  no   includes:  **/gitmetadata/** exludes:  ''    opa5  no  OPA5 is enabled  includes:  **/*.* excludes:  ''    opensourceConfiguration  no   includes:  **/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk excludes:  ''    pipelineConfigAndTests  no   includes:  .pipeline/*.* excludes:  ''    securityDescriptor  no   includes:  **/xs-security.json exludes:  ''    sonar  no   includes:  **/jacoco*.exec, **/sonar-project.properties exludes:  ''    tests  no   includes:  **/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js excludes:  ''      Overwriting default stashing behavior  It is possible to overwrite the default behavior of the stashes using the parameters  stashIncludes  and  stashExcludes  , e.g.   stashIncludes: [buildDescriptor: '**/mybuild.yml]  stashExcludes: [tests: '**/NOTRELEVANT.*]", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/pipelineStashFiles/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   runOpaTests  runCheckmarx  stashExcludes  stashIncludes", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/pipelineStashFiles/#explanation-of-pipeline-step", 
            "text": "Usage of pipeline step:  pipelineStashFiles   script:   this   { \n   mavenExecute   script:   this ,   ...  }", 
            "title": "Explanation of pipeline step"
        }, 
        {
            "location": "/steps/prepareDefaultValues/", 
            "text": "prepareDefaultValues\n\n\nDescription\n\n\nLoads the pipeline library default values from the file \nresources/default_pipeline_environment.yml\n.\nAfterwards the values can be loaded by the method: \nConfigurationLoader.defaultStepConfiguration\n \n\n\nParameters\n\n\nNone\n\n\nStep configuration\n\n\nNone\n\n\nExceptions\n\n\nNone\n\n\nExample\n\n\nprepareDefaultValues\n()", 
            "title": "prepareDefaultValues"
        }, 
        {
            "location": "/steps/prepareDefaultValues/#preparedefaultvalues", 
            "text": "", 
            "title": "prepareDefaultValues"
        }, 
        {
            "location": "/steps/prepareDefaultValues/#description", 
            "text": "Loads the pipeline library default values from the file  resources/default_pipeline_environment.yml .\nAfterwards the values can be loaded by the method:  ConfigurationLoader.defaultStepConfiguration", 
            "title": "Description"
        }, 
        {
            "location": "/steps/prepareDefaultValues/#parameters", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/prepareDefaultValues/#step-configuration", 
            "text": "None", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/prepareDefaultValues/#exceptions", 
            "text": "None", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/prepareDefaultValues/#example", 
            "text": "prepareDefaultValues ()", 
            "title": "Example"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/", 
            "text": "setupCommonPipelineEnvironment\n\n\nDescription\n\n\nInitializes the \ncommonPipelineEnvironment\n, which is used throughout the complete pipeline.\n\n\n\n\nTip\n\n\nThis step needs to run at the beginning of a pipeline right after the SCM checkout.\nThen subsequent pipeline steps consume the information from \ncommonPipelineEnvironment\n; it does not need to be passed to pipeline steps explicitly.\n\n\n\n\nPrerequisites\n\n\n\n\nA \nconfiguration file\n with properties (default location: \n.pipeline/config.properties\n). The property values are used as default values in many pipeline steps.\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n-\n\n\n\n\n\n\n\n\nconfigFile\n\n\nno\n\n\n.pipeline/config.properties\n\n\n\n\n\n\n\n\n\n\n\n\nscript\n - The reference to the pipeline script (Jenkinsfile). Normally \nthis\n needs to be provided.\n\n\nconfigFile\n - Property file defining project specific settings.\n\n\n\n\nStep configuration\n\n\nnone\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\nnone \n\n\nExample\n\n\nsetupCommonPipelineEnvironment\n \nscript:\n \nthis", 
            "title": "setupCommonPipelineEnvironment"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#setupcommonpipelineenvironment", 
            "text": "", 
            "title": "setupCommonPipelineEnvironment"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#description", 
            "text": "Initializes the  commonPipelineEnvironment , which is used throughout the complete pipeline.   Tip  This step needs to run at the beginning of a pipeline right after the SCM checkout.\nThen subsequent pipeline steps consume the information from  commonPipelineEnvironment ; it does not need to be passed to pipeline steps explicitly.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#prerequisites", 
            "text": "A  configuration file  with properties (default location:  .pipeline/config.properties ). The property values are used as default values in many pipeline steps.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  yes  -     configFile  no  .pipeline/config.properties       script  - The reference to the pipeline script (Jenkinsfile). Normally  this  needs to be provided.  configFile  - Property file defining project specific settings.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#step-configuration", 
            "text": "none", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#return-value", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#side-effects", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#exceptions", 
            "text": "none", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/setupCommonPipelineEnvironment/#example", 
            "text": "setupCommonPipelineEnvironment   script:   this", 
            "title": "Example"
        }, 
        {
            "location": "/steps/toolValidate/", 
            "text": "toolValidate\n\n\nDescription\n\n\nChecks the existence and compatibility of a tool, necessary for a successful pipeline execution.\nIn case a violation is found, an exception is raised.\n\n\nPrerequisites\n\n\nnone\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\ntool\n\n\nyes\n\n\n\n\n'java', 'mta', 'neo'\n\n\n\n\n\n\nhome\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntool\n The tool that is checked for existence and compatible version.\n\n\nhome\n The location in the file system where Jenkins can access the tool.\n\n\n\n\nStep configuration\n\n\nnone\n\n\nReturn value\n\n\nnone\n\n\nSide effects\n\n\nnone\n\n\nExceptions\n\n\n\n\nIllegalArgumentException\n:\n\n\nIf at least one of the parameters  \ntool\n, \nhome\n is not provided.\n\n\n\n\n\n\nAbortException\n:\n\n\nIf \ntool\n is not supported.\n\n\n\n\n\n\n\n\nExample\n\n\ntoolValidate\n \ntool:\n \nneo\n,\n \nhome:\n/path/to/neo-java-web-sdk", 
            "title": "toolValidate"
        }, 
        {
            "location": "/steps/toolValidate/#toolvalidate", 
            "text": "", 
            "title": "toolValidate"
        }, 
        {
            "location": "/steps/toolValidate/#description", 
            "text": "Checks the existence and compatibility of a tool, necessary for a successful pipeline execution.\nIn case a violation is found, an exception is raised.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/toolValidate/#prerequisites", 
            "text": "none", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/toolValidate/#parameters", 
            "text": "parameter  mandatory  default  possible values      tool  yes   'java', 'mta', 'neo'    home  yes        tool  The tool that is checked for existence and compatible version.  home  The location in the file system where Jenkins can access the tool.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/toolValidate/#step-configuration", 
            "text": "none", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/toolValidate/#return-value", 
            "text": "none", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/toolValidate/#side-effects", 
            "text": "none", 
            "title": "Side effects"
        }, 
        {
            "location": "/steps/toolValidate/#exceptions", 
            "text": "IllegalArgumentException :  If at least one of the parameters   tool ,  home  is not provided.    AbortException :  If  tool  is not supported.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/toolValidate/#example", 
            "text": "toolValidate   tool:   neo ,   home: /path/to/neo-java-web-sdk", 
            "title": "Example"
        }, 
        {
            "location": "/steps/transportRequestCreate/", 
            "text": "transportRequestCreate\n\n\nDescription\n\n\nCreates a Transport Request for a Change Document on the Solution Manager.\n\n\nPrerequisites\n\n\n\n\nChange Management Client 2.0.0 or compatible version\n - available for download on Maven Central.\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nchangeDocumentId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncredentialsId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nendpoint\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nclientOpts\n\n\nno\n\n\n\n\n\n\n\n\n\n\ngitFrom\n\n\nno\n\n\norigin/master\n\n\n\n\n\n\n\n\ngitTo\n\n\nno\n\n\nHEAD\n\n\n\n\n\n\n\n\ngitChangeDocumentLabel\n\n\nno\n\n\nChangeDocument\\s?:\n\n\nregex pattern\n\n\n\n\n\n\ngitFormat\n\n\nno\n\n\n%b\n\n\nsee \ngit log --help\n\n\n\n\n\n\n\n\n\n\nscript\n - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the \nthis\n parameter, as in \nscript: this\n. This allows the function to access the \ncommonPipelineEnvironment\n for retrieving, for example, configuration parameters.\n\n\nchangeDocumentId\n - The id of the change document to transport.\n\n\ncredentialsId\n - The credentials to connect to the Solution Manager.\n\n\nendpoint\n - The address of the Solution Manager.\n\n\nclientOpts\n- Options forwarded to JVM used by the CM client, like \nJAVA_OPTS\n\n\ngitFrom\n - The starting point for retrieving the change document id\n\n\ngitTo\n - The end point for retrieving the change document id\n\n\ngitChangeDocumentLabel\n - A pattern used for identifying lines holding the change document id.\n\n\ngitFormat\n - Specifies what part of the commit is scanned. By default the body of the commit message is scanned.\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\ncredentialsId\n\n\nendpoint\n\n\nclientOpts\n\n\n\n\nReturn value\n\n\nThe id of the Transport Request that has been created.\n\n\nExceptions\n\n\n\n\nAbortException\n:\n\n\nIf the change id is not provided.\n\n\nIf the creation of the transport request fails.\n\n\n\n\n\n\n\n\nExample\n\n\ndef\n \ntransportRequestId\n \n=\n \ntransportRequestCreate\n \nscript:\nthis\n,\n \nchangeDocumentId:\n \n001", 
            "title": "transportRequestCreate"
        }, 
        {
            "location": "/steps/transportRequestCreate/#transportrequestcreate", 
            "text": "", 
            "title": "transportRequestCreate"
        }, 
        {
            "location": "/steps/transportRequestCreate/#description", 
            "text": "Creates a Transport Request for a Change Document on the Solution Manager.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/transportRequestCreate/#prerequisites", 
            "text": "Change Management Client 2.0.0 or compatible version  - available for download on Maven Central.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/transportRequestCreate/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  yes      changeDocumentId  yes      credentialsId  yes      endpoint  yes      clientOpts  no      gitFrom  no  origin/master     gitTo  no  HEAD     gitChangeDocumentLabel  no  ChangeDocument\\s?:  regex pattern    gitFormat  no  %b  see  git log --help      script  - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the  this  parameter, as in  script: this . This allows the function to access the  commonPipelineEnvironment  for retrieving, for example, configuration parameters.  changeDocumentId  - The id of the change document to transport.  credentialsId  - The credentials to connect to the Solution Manager.  endpoint  - The address of the Solution Manager.  clientOpts - Options forwarded to JVM used by the CM client, like  JAVA_OPTS  gitFrom  - The starting point for retrieving the change document id  gitTo  - The end point for retrieving the change document id  gitChangeDocumentLabel  - A pattern used for identifying lines holding the change document id.  gitFormat  - Specifies what part of the commit is scanned. By default the body of the commit message is scanned.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/transportRequestCreate/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   credentialsId  endpoint  clientOpts", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/transportRequestCreate/#return-value", 
            "text": "The id of the Transport Request that has been created.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/transportRequestCreate/#exceptions", 
            "text": "AbortException :  If the change id is not provided.  If the creation of the transport request fails.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/transportRequestCreate/#example", 
            "text": "def   transportRequestId   =   transportRequestCreate   script: this ,   changeDocumentId:   001", 
            "title": "Example"
        }, 
        {
            "location": "/steps/transportRequestRelease/", 
            "text": "transportRequestRelease\n\n\nDescription\n\n\nReleases a Transport Request for a Change Document on the Solution Manager.\n\n\nPrerequisites\n\n\n\n\nChange Management Client 2.0.0 or compatible version\n - available for download on Maven Central.\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nchangeDocumentId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ntransportRequestId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncredentialsId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nendpoint\n\n\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscript\n - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the \nthis\n parameter, as in \nscript: this\n. This allows the function to access the \ncommonPipelineEnvironment\n for retrieving, for example, configuration parameters.\n\n\nchangeDocumentId\n - The id of the change document related to the transport request to release.\n\n\ntransportRequestId\n - The id of the transport request to release.\n\n\ncredentialsId\n - The credentials to connect to the Solution Manager.\n\n\nendpoint\n - The address of the Solution Manager.\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\ncredentialsId\n\n\nendpoint\n\n\n\n\nReturn value\n\n\nNone.\n\n\nExceptions\n\n\n\n\nAbortException\n:\n\n\nIf the change id is not provided.\n\n\nIf the transport request id is not provided.\n\n\nIf the release of the transport request fails.\n\n\n\n\n\n\n\n\nExample\n\n\ntransportRequestRelease\n \nscript:\nthis\n,\n \nchangeDocumentId:\n \n001\n,\n \ntransportRequestId:\n \n001", 
            "title": "transportRequestRelease"
        }, 
        {
            "location": "/steps/transportRequestRelease/#transportrequestrelease", 
            "text": "", 
            "title": "transportRequestRelease"
        }, 
        {
            "location": "/steps/transportRequestRelease/#description", 
            "text": "Releases a Transport Request for a Change Document on the Solution Manager.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/transportRequestRelease/#prerequisites", 
            "text": "Change Management Client 2.0.0 or compatible version  - available for download on Maven Central.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/transportRequestRelease/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  yes      changeDocumentId  yes      transportRequestId  yes      credentialsId  yes      endpoint  yes        script  - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the  this  parameter, as in  script: this . This allows the function to access the  commonPipelineEnvironment  for retrieving, for example, configuration parameters.  changeDocumentId  - The id of the change document related to the transport request to release.  transportRequestId  - The id of the transport request to release.  credentialsId  - The credentials to connect to the Solution Manager.  endpoint  - The address of the Solution Manager.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/transportRequestRelease/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   credentialsId  endpoint", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/transportRequestRelease/#return-value", 
            "text": "None.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/transportRequestRelease/#exceptions", 
            "text": "AbortException :  If the change id is not provided.  If the transport request id is not provided.  If the release of the transport request fails.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/transportRequestRelease/#example", 
            "text": "transportRequestRelease   script: this ,   changeDocumentId:   001 ,   transportRequestId:   001", 
            "title": "Example"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/", 
            "text": "transportRequestUploadFile\n\n\nDescription\n\n\nUploads a file to a Transport Request for a Change Document on the Solution Manager.\n\n\nPrerequisites\n\n\n\n\nChange Management Client 2.0.0 or compatible version\n - available for download on Maven Central.\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nparameter\n\n\nmandatory\n\n\ndefault\n\n\npossible values\n\n\n\n\n\n\n\n\n\n\nscript\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nchangeDocumentId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ntransportRequestId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\napplicationId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nfilePath\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ncredentialsId\n\n\nyes\n\n\n\n\n\n\n\n\n\n\nendpoint\n\n\nyes\n\n\n\n\n\n\n\n\n\n\ngitFrom\n\n\nno\n\n\norigin/master\n\n\n\n\n\n\n\n\ngitTo\n\n\nno\n\n\nHEAD\n\n\n\n\n\n\n\n\ngitChangeDocumentLabel\n\n\nno\n\n\nChangeDocument\\s?:\n\n\nregex pattern\n\n\n\n\n\n\ngitFormat\n\n\nno\n\n\n%b\n\n\nsee \ngit log --help\n\n\n\n\n\n\n\n\n\n\nscript\n - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the \nthis\n parameter, as in \nscript: this\n. This allows the function to access the \ncommonPipelineEnvironment\n for retrieving, for example, configuration parameters.\n\n\nchangeDocumentId\n - The id of the change document related to the transport request to release.\n\n\ntransportRequestId\n - The id of the transport request to release.\n\n\napplicationId\n - The id of the application.\n\n\nfilePath\n - The path of the file to upload.\n\n\ncredentialsId\n - The credentials to connect to the Solution Manager.\n\n\nendpoint\n - The address of the Solution Manager.\n\n\ngitFrom\n - The starting point for retrieving the change document id\n\n\ngitTo\n - The end point for retrieving the change document id\n\n\ngitChangeDocumentLabel\n - A pattern used for identifying lines holding the change document id.\n\n\ngitFormat\n - Specifies what part of the commit is scanned. By default the body of the commit message is scanned.\n\n\n\n\nStep configuration\n\n\nThe following parameters can also be specified as step parameters using the global configuration file:\n\n\n\n\ncredentialsId\n\n\nendpoint\n\n\n\n\nReturn value\n\n\nNone.\n\n\nExceptions\n\n\n\n\nAbortException\n:\n\n\nIf the change id is not provided.\n\n\nIf the transport request id is not provided.\n\n\nIf the application id is not provided.\n\n\nIf the file path is not provided.\n\n\nIf the upload fails.\n\n\n\n\n\n\n\n\nExample\n\n\ntransportRequestUploadFile\n \nscript:\nthis\n,\n \nchangeDocumentId:\n \n001\n,\n \ntransportRequestId:\n \n001\n,\n \napplicationId:\n \n001\n,\n \nfilePath:\n \n/path", 
            "title": "transportRequestUploadFile"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/#transportrequestuploadfile", 
            "text": "", 
            "title": "transportRequestUploadFile"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/#description", 
            "text": "Uploads a file to a Transport Request for a Change Document on the Solution Manager.", 
            "title": "Description"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/#prerequisites", 
            "text": "Change Management Client 2.0.0 or compatible version  - available for download on Maven Central.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/#parameters", 
            "text": "parameter  mandatory  default  possible values      script  yes      changeDocumentId  yes      transportRequestId  yes      applicationId  yes      filePath  yes      credentialsId  yes      endpoint  yes      gitFrom  no  origin/master     gitTo  no  HEAD     gitChangeDocumentLabel  no  ChangeDocument\\s?:  regex pattern    gitFormat  no  %b  see  git log --help      script  - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the  this  parameter, as in  script: this . This allows the function to access the  commonPipelineEnvironment  for retrieving, for example, configuration parameters.  changeDocumentId  - The id of the change document related to the transport request to release.  transportRequestId  - The id of the transport request to release.  applicationId  - The id of the application.  filePath  - The path of the file to upload.  credentialsId  - The credentials to connect to the Solution Manager.  endpoint  - The address of the Solution Manager.  gitFrom  - The starting point for retrieving the change document id  gitTo  - The end point for retrieving the change document id  gitChangeDocumentLabel  - A pattern used for identifying lines holding the change document id.  gitFormat  - Specifies what part of the commit is scanned. By default the body of the commit message is scanned.", 
            "title": "Parameters"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/#step-configuration", 
            "text": "The following parameters can also be specified as step parameters using the global configuration file:   credentialsId  endpoint", 
            "title": "Step configuration"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/#return-value", 
            "text": "None.", 
            "title": "Return value"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/#exceptions", 
            "text": "AbortException :  If the change id is not provided.  If the transport request id is not provided.  If the application id is not provided.  If the file path is not provided.  If the upload fails.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/steps/transportRequestUploadFile/#example", 
            "text": "transportRequestUploadFile   script: this ,   changeDocumentId:   001 ,   transportRequestId:   001 ,   applicationId:   001 ,   filePath:   /path", 
            "title": "Example"
        }, 
        {
            "location": "/jenkins/requiredPlugins/", 
            "text": "Required Plugins\n\n\nThe following Jenkins plugins are needed in order to use the Piper Library.\nThe list below contains the plugin Id and version of the plugin.\n\n\nPlugins\n\n\n\n\nace-editor 1.1\n\n\nauthentication-tokens 1.3\n\n\nbouncycastle-api 2.16.2\n\n\nbranch-api 2.0.14\n\n\ncloudbees-folder 6.2.1\n\n\ncredentials 2.1.16\n\n\ncredentials-binding 1.13\n\n\ndisplay-url-api 2.1.0\n\n\ndocker-commons 1.9\n\n\ndocker-workflow 1.10\n\n\ndurable-task 1.15\n\n\ngit 3.6.2\n\n\ngit-client 2.5.0\n\n\ngit-server 1.7\n\n\nhandlebars 1.1.1\n\n\nicon-shim 2.0.3\n\n\njquery-detached 1.2.1\n\n\njunit 1.21\n\n\nmailer 1.20\n\n\nmatrix-project 1.12\n\n\nmomentjs 1.1.1\n\n\npipeline-build-step 2.5.1\n\n\npipeline-graph-analysis 1.3\n\n\npipeline-input-step 2.8\n\n\npipeline-milestone-step 1.3.1\n\n\npipeline-model-api 1.2.2\n\n\npipeline-model-definition 1.1.1\n\n\npipeline-model-extensions 1.1.1\n\n\npipeline-rest-api 2.6\n\n\npipeline-stage-step 2.2\n\n\npipeline-stage-tags-metadata 1.2.2\n\n\npipeline-stage-view 2.6\n\n\npipeline-utility-steps 1.3.0\n\n\nplain-credentials 1.4\n\n\nscm-api 2.2.3\n\n\nscript-security 1.34\n\n\nssh-credentials 1.13\n\n\nstructs 1.10\n\n\nworkflow-aggregator 2.5\n\n\nworkflow-api 2.23.1\n\n\nworkflow-basic-steps 2.6\n\n\nworkflow-cps 2.41\n\n\nworkflow-cps-global-lib 2.7\n\n\nworkflow-durable-task-step 2.17\n\n\nworkflow-job 2.12.2\n\n\nworkflow-multibranch 2.14\n\n\nworkflow-scm-step 2.6\n\n\nworkflow-step-api 2.13\n\n\nworkflow-support 2.16", 
            "title": "Required Plugins"
        }, 
        {
            "location": "/jenkins/requiredPlugins/#required-plugins", 
            "text": "The following Jenkins plugins are needed in order to use the Piper Library.\nThe list below contains the plugin Id and version of the plugin.  Plugins   ace-editor 1.1  authentication-tokens 1.3  bouncycastle-api 2.16.2  branch-api 2.0.14  cloudbees-folder 6.2.1  credentials 2.1.16  credentials-binding 1.13  display-url-api 2.1.0  docker-commons 1.9  docker-workflow 1.10  durable-task 1.15  git 3.6.2  git-client 2.5.0  git-server 1.7  handlebars 1.1.1  icon-shim 2.0.3  jquery-detached 1.2.1  junit 1.21  mailer 1.20  matrix-project 1.12  momentjs 1.1.1  pipeline-build-step 2.5.1  pipeline-graph-analysis 1.3  pipeline-input-step 2.8  pipeline-milestone-step 1.3.1  pipeline-model-api 1.2.2  pipeline-model-definition 1.1.1  pipeline-model-extensions 1.1.1  pipeline-rest-api 2.6  pipeline-stage-step 2.2  pipeline-stage-tags-metadata 1.2.2  pipeline-stage-view 2.6  pipeline-utility-steps 1.3.0  plain-credentials 1.4  scm-api 2.2.3  script-security 1.34  ssh-credentials 1.13  structs 1.10  workflow-aggregator 2.5  workflow-api 2.23.1  workflow-basic-steps 2.6  workflow-cps 2.41  workflow-cps-global-lib 2.7  workflow-durable-task-step 2.17  workflow-job 2.12.2  workflow-multibranch 2.14  workflow-scm-step 2.6  workflow-step-api 2.13  workflow-support 2.16", 
            "title": "Required Plugins"
        }
    ]
}